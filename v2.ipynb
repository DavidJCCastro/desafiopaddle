{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ae9ede-8149-4e1b-89f5-4f22ad94d8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcd4dd1-b0c5-4762-acc9-456404120ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_video(input_path, output_path, calibration_images=None):\n",
    "    \"\"\"\n",
    "    Remove lens distortion from a video file\n",
    "    \n",
    "    Parameters:\n",
    "    - input_path: Path to the input video file\n",
    "    - output_path: Path to save the undistorted video\n",
    "    - calibration_images: Optional list of paths to chessboard images for calibration\n",
    "                         If None, uses default estimation values\n",
    "    \"\"\"\n",
    "    # Use estimated values for a typical wide-angle camera\n",
    "    # These are default values, adjust based on your specific camera if known\n",
    "    print(\"Using default camera parameters (no calibration images provided)\")\n",
    "    # Camera matrix (focal length and optical centers)\n",
    "    mtx = np.array([\n",
    "        [1000, 0, 960],  # fx, 0, cx\n",
    "        [0, 1000, 540],  # 0, fy, cy\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist = np.array([[-0.3, 0.1, 0, 0, -0.02]])\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate optimal camera matrix\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (width, height), 1, (width, height))\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    frame_idx = 0\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Undistort the frame\n",
    "            dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "            \n",
    "            # Crop the image (optional)\n",
    "            x, y, w, h = roi\n",
    "            dst = dst[y:y+h, x:x+w]\n",
    "            \n",
    "            # Resize back to original dimensions if needed\n",
    "            if dst.shape[1] != width or dst.shape[0] != height:\n",
    "                dst = cv2.resize(dst, (width, height))\n",
    "            \n",
    "            # Write the undistorted frame\n",
    "            out.write(dst)\n",
    "            \n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Undistorted video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcb42d4-8cb1-4aa8-9ba8-657efb03e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default camera parameters (no calibration images provided)\n",
      "Processing video with 301 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████▊| 300/301 [00:14<00:00, 20.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undistorted video saved to undist.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undistort_video(\"10secs.mp4\", \"undist.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8856c1-5220-403f-8903-282b911ec279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_court_lines(frame):\n",
    "    \"\"\"\n",
    "    Detect court lines using Hough Line Transform\n",
    "    Returns the court corners if found\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Use adaptive thresholding to identify court lines\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "    \n",
    "    # Find edges\n",
    "    edges = cv2.Canny(thresh, 50, 150)\n",
    "    \n",
    "    # Dilate to connect edge components\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Find lines using HoughLinesP\n",
    "    lines = cv2.HoughLinesP(\n",
    "        dilated, 1, np.pi/180, threshold=50, \n",
    "        minLineLength=50, maxLineGap=10\n",
    "    )\n",
    "    \n",
    "    if lines is None:\n",
    "        return None\n",
    "    \n",
    "    # Draw lines on a copy of the frame for visualization\n",
    "    line_frame = frame.copy()\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # For debugging: save the line detection result\n",
    "    cv2.imwrite(\"court_lines_detected.jpg\", line_frame)\n",
    "    \n",
    "    # Group lines into horizontal and vertical\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Calculate angle\n",
    "        angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "        \n",
    "        # Group based on angle\n",
    "        if angle < 45 or angle > 135:  # Horizontal lines\n",
    "            h_lines.append(line[0])\n",
    "        else:  # Vertical lines\n",
    "            v_lines.append(line[0])\n",
    "    \n",
    "    # If we don't have enough lines, return None\n",
    "    if len(h_lines) < 2 or len(v_lines) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Find boundary lines (furthest lines in each direction)\n",
    "    h_lines = sorted(h_lines, key=lambda line: (line[1] + line[3]) / 2)  # Sort by y-coordinate\n",
    "    v_lines = sorted(v_lines, key=lambda line: (line[0] + line[2]) / 2)  # Sort by x-coordinate\n",
    "    \n",
    "    top_line = h_lines[0]\n",
    "    bottom_line = h_lines[-1]\n",
    "    left_line = v_lines[0]\n",
    "    right_line = v_lines[-1]\n",
    "    \n",
    "    # Find intersections of these lines to get court corners\n",
    "    top_left = line_intersection(top_line, left_line)\n",
    "    top_right = line_intersection(top_line, right_line)\n",
    "    bottom_left = line_intersection(bottom_line, left_line)\n",
    "    bottom_right = line_intersection(bottom_line, right_line)\n",
    "    \n",
    "    # Convert to integer points\n",
    "    corners = [\n",
    "        (int(top_left[0]), int(top_left[1])),\n",
    "        (int(top_right[0]), int(top_right[1])),\n",
    "        (int(bottom_right[0]), int(bottom_right[1])),\n",
    "        (int(bottom_left[0]), int(bottom_left[1]))\n",
    "    ]\n",
    "    \n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fa474c-ffe0-4745-bcaa-3a4c0d4cdbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_intersection(line1, line2):\n",
    "    \"\"\"Find the intersection point of two lines\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    \n",
    "    # Line 1 represented as a1x + b1y = c1\n",
    "    a1 = y2 - y1\n",
    "    b1 = x1 - x2\n",
    "    c1 = a1 * x1 + b1 * y1\n",
    "    \n",
    "    # Line 2 represented as a2x + b2y = c2\n",
    "    a2 = y4 - y3\n",
    "    b2 = x3 - x4\n",
    "    c2 = a2 * x3 + b2 * y3\n",
    "    \n",
    "    determinant = a1 * b2 - a2 * b1\n",
    "    \n",
    "    if determinant == 0:\n",
    "        # Lines are parallel\n",
    "        return (0, 0)\n",
    "    else:\n",
    "        x = (b2 * c1 - b1 * c2) / determinant\n",
    "        y = (a1 * c2 - a2 * c1) / determinant\n",
    "        return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e88198-1da3-4a94-9466-3acb5e47a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_court_selection(frame):\n",
    "    \"\"\"\n",
    "    Allow manual selection of court corners if automatic detection fails\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            corners.append((x, y))\n",
    "            # Draw circle at selected point\n",
    "            cv2.circle(display_frame, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow('Select Court Corners', display_frame)\n",
    "            \n",
    "            if len(corners) == 4:\n",
    "                cv2.destroyWindow('Select Court Corners')\n",
    "    \n",
    "    # Create a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "    cv2.namedWindow('Select Court Corners')\n",
    "    cv2.setMouseCallback('Select Court Corners', mouse_callback)\n",
    "    \n",
    "    # Display instructions\n",
    "    text = \"Click on 4 court corners in order: Top-Left, Top-Right, Bottom-Right, Bottom-Left\"\n",
    "    y_pos = 30\n",
    "    for i, line in enumerate(text.split(', ')):\n",
    "        cv2.putText(display_frame, line, (10, y_pos + i*30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Select Court Corners', display_frame)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    return corners if len(corners) == 4 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fca63f2-7b1a-4263-b63b-b46af443f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(frame, corners, target_width=800, target_height=400):\n",
    "    \"\"\"\n",
    "    Apply perspective transformation to get a top-down view of the court\n",
    "    \"\"\"\n",
    "    # Define the destination points (rectangle)\n",
    "    dst_points = np.array([\n",
    "        [0, 0],                      # Top-left\n",
    "        [target_width, 0],           # Top-right\n",
    "        [target_width, target_height], # Bottom-right\n",
    "        [0, target_height]           # Bottom-left\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Convert corners to numpy array\n",
    "    src_points = np.array(corners, dtype=np.float32)\n",
    "    \n",
    "    # Compute perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    \n",
    "    # Apply transformation\n",
    "    warped = cv2.warpPerspective(frame, M, (target_width, target_height))\n",
    "    \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a89556-c52c-45b3-b282-d132af813d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_perspective_transform(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process a video to detect court and transform perspective\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Read first frame for court detection\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Try automatic court detection\n",
    "    corners = detect_court_lines(first_frame)\n",
    "    \n",
    "    # If automatic detection fails, use manual selection\n",
    "    if corners is None or len(corners) != 4:\n",
    "        print(\"Automatic court detection failed. Please select court corners manually.\")\n",
    "        corners = manual_court_selection(first_frame)\n",
    "        \n",
    "        if corners is None or len(corners) != 4:\n",
    "            print(\"Court corner selection failed\")\n",
    "            return False\n",
    "    \n",
    "    # Apply perspective transform\n",
    "    target_width, target_height = 800, 400  # Standard padel court dimensions (scaled)\n",
    "    _, perspective_matrix = apply_perspective_transform(first_frame, corners, target_width, target_height)\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (target_width, target_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply perspective transform\n",
    "            warped_frame, _ = apply_perspective_transform(\n",
    "                frame, corners, target_width, target_height\n",
    "            )\n",
    "            \n",
    "            # Write transformed frame\n",
    "            out.write(warped_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Perspective-corrected video saved to {output_path}\")\n",
    "    \n",
    "    # Save the perspective matrix for future use in player tracking\n",
    "    np.save(\"perspective_matrix.npy\", perspective_matrix)\n",
    "    print(\"Perspective transformation matrix saved to perspective_matrix.npy\")\n",
    "    \n",
    "    return True, perspective_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c157970-de18-4d34-b36e-2b704dd7ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video with 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 300/300 [00:02<00:00, 133.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perspective-corrected video saved to new.mp4\n",
      "Perspective transformation matrix saved to perspective_matrix.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "succ, trans = process_video_with_perspective_transform(\"undist.mp4\", \"new.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb60eefc-6719-4b85-bc4f-c9f27431e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_court_features(frame):\n",
    "    \"\"\"\n",
    "    Enhance the visibility of court lines and features\n",
    "    \"\"\"\n",
    "    # Convert to HSV for better color segmentation\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create mask for white lines\n",
    "    # White in HSV has high V, low S, and any H\n",
    "    lower_white = np.array([0, 0, 180])\n",
    "    upper_white = np.array([180, 70, 255])\n",
    "    white_mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Combine white mask with enhanced image\n",
    "    combined = cv2.bitwise_or(enhanced, enhanced, mask=white_mask)\n",
    "    \n",
    "    # Save intermediate results for debugging\n",
    "    cv2.imwrite(\"white_mask.jpg\", white_mask)\n",
    "    cv2.imwrite(\"enhanced_features.jpg\", combined)\n",
    "    \n",
    "    return combined, white_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2862c36d-075d-4f09-b651-22ef3e3bc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_specific_court_lines(frame):\n",
    "    \"\"\"\n",
    "    Detect specific court lines: bottom field line, middle line, and net line\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # Enhance court features\n",
    "    enhanced, white_mask = enhance_court_features(frame)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Dilate to connect edge components\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Save intermediate results for debugging\n",
    "    cv2.imwrite(\"edges_detected.jpg\", edges)\n",
    "    \n",
    "    # Detect lines using Hough Line Transform\n",
    "    lines = cv2.HoughLinesP(\n",
    "        dilated, 1, np.pi/180, threshold=50, \n",
    "        minLineLength=width//3,  # At least 1/3 of width to filter small noisy lines\n",
    "        maxLineGap=20\n",
    "    )\n",
    "    \n",
    "    if lines is None or len(lines) < 3:\n",
    "        print(\"Not enough lines detected, try using manual selection\")\n",
    "        return None\n",
    "    \n",
    "    # Visualization for debugging\n",
    "    line_frame = frame.copy()\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imwrite(\"all_lines_detected.jpg\", line_frame)\n",
    "    \n",
    "    # Separate horizontal and vertical lines\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Calculate angle and length\n",
    "        angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        \n",
    "        # Group based on angle\n",
    "        if angle < 30 or angle > 150:  # Horizontal-ish lines\n",
    "            h_lines.append((line[0], y1, length))  # Store with y-coordinate and length\n",
    "        elif 60 < angle < 120:  # Vertical-ish lines\n",
    "            v_lines.append((line[0], x1, length))  # Store with x-coordinate and length\n",
    "    \n",
    "    # Sort horizontal lines by y-coordinate (top to bottom)\n",
    "    h_lines.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Get specific horizontal lines we need\n",
    "    if len(h_lines) < 2:\n",
    "        print(\"Not enough horizontal lines detected\")\n",
    "        return None\n",
    "    \n",
    "    # Find the net line (typically in the upper half, and usually one of the stronger white lines)\n",
    "    # Use white mask to help identify it\n",
    "    net_line_candidates = []\n",
    "    \n",
    "    for line_data in h_lines:\n",
    "        line, y_coord, length = line_data\n",
    "        x1, y1, x2, y2 = line\n",
    "        \n",
    "        # Check if this line is in the upper half of the image\n",
    "        if y1 < height // 2:\n",
    "            # Create a thin mask around this line\n",
    "            line_mask = np.zeros_like(white_mask)\n",
    "            cv2.line(line_mask, (x1, y1), (x2, y2), 255, 5)\n",
    "            \n",
    "            # Count white pixels along this line in the white mask\n",
    "            white_pixels = cv2.countNonZero(cv2.bitwise_and(white_mask, line_mask))\n",
    "            \n",
    "            # Add to candidates with a score (white pixels * length)\n",
    "            score = white_pixels * length\n",
    "            net_line_candidates.append((line_data, score))\n",
    "    \n",
    "    # Sort by score and select top candidate\n",
    "    if net_line_candidates:\n",
    "        net_line_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        net_line_data = net_line_candidates[0][0]\n",
    "    else:\n",
    "        # Fallback: use the highest line in upper half\n",
    "        upper_lines = [l for l in h_lines if l[1] < height // 2]\n",
    "        if upper_lines:\n",
    "            net_line_data = upper_lines[0]\n",
    "        else:\n",
    "            print(\"Could not identify net line\")\n",
    "            return None\n",
    "    \n",
    "    # Find bottom field line (should be in lower part of image)\n",
    "    bottom_line_candidates = [l for l in h_lines if l[1] > height * 0.6]\n",
    "    \n",
    "    if bottom_line_candidates:\n",
    "        # Sort by length to get the most complete line\n",
    "        bottom_line_candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "        bottom_line_data = bottom_line_candidates[0]\n",
    "    else:\n",
    "        # Fallback: use the lowest horizontal line\n",
    "        bottom_line_data = h_lines[-1]\n",
    "    \n",
    "    # Find middle court line (between net and bottom)\n",
    "    mid_y = (net_line_data[1] + bottom_line_data[1]) / 2\n",
    "    middle_line_data = min(h_lines, key=lambda x: abs(x[1] - mid_y))\n",
    "    \n",
    "    # Get the actual line data\n",
    "    net_line = net_line_data[0]\n",
    "    middle_line = middle_line_data[0]\n",
    "    bottom_line = bottom_line_data[0]\n",
    "    \n",
    "    # Now find vertical lines (usually the sides of the court)\n",
    "    if len(v_lines) < 2:\n",
    "        print(\"Not enough vertical lines detected\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by x-coordinate\n",
    "    v_lines.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Get leftmost and rightmost vertical lines\n",
    "    left_line = v_lines[0][0]\n",
    "    right_line = v_lines[-1][0]\n",
    "    \n",
    "    # Visualization for debugging - show the specific lines we're using\n",
    "    key_lines_frame = frame.copy()\n",
    "    cv2.line(key_lines_frame, (net_line[0], net_line[1]), (net_line[2], net_line[3]), (255, 0, 0), 3)  # Net line in blue\n",
    "    cv2.line(key_lines_frame, (middle_line[0], middle_line[1]), (middle_line[2], middle_line[3]), (0, 255, 0), 3)  # Middle line in green\n",
    "    cv2.line(key_lines_frame, (bottom_line[0], bottom_line[1]), (bottom_line[2], bottom_line[3]), (0, 0, 255), 3)  # Bottom line in red\n",
    "    cv2.line(key_lines_frame, (left_line[0], left_line[1]), (left_line[2], left_line[3]), (255, 255, 0), 3)  # Left line in cyan\n",
    "    cv2.line(key_lines_frame, (right_line[0], right_line[1]), (right_line[2], right_line[3]), (255, 0, 255), 3)  # Right line in magenta\n",
    "    \n",
    "    cv2.imwrite(\"key_court_lines.jpg\", key_lines_frame)\n",
    "    \n",
    "    # Calculate intersections to find the court corners\n",
    "    try:\n",
    "        # Top corners (using net line)\n",
    "        top_left = line_intersection(net_line, left_line)\n",
    "        top_right = line_intersection(net_line, right_line)\n",
    "        \n",
    "        # Bottom corners\n",
    "        bottom_left = line_intersection(bottom_line, left_line)\n",
    "        bottom_right = line_intersection(bottom_line, right_line)\n",
    "        \n",
    "        # Convert to integer points\n",
    "        corners = [\n",
    "            (int(top_left[0]), int(top_left[1])),\n",
    "            (int(top_right[0]), int(top_right[1])),\n",
    "            (int(bottom_right[0]), int(bottom_right[1])),\n",
    "            (int(bottom_left[0]), int(bottom_left[1]))\n",
    "        ]\n",
    "        \n",
    "        # Draw the detected corners\n",
    "        corner_frame = frame.copy()\n",
    "        for i, corner in enumerate(corners):\n",
    "            cv2.circle(corner_frame, corner, 10, (0, 0, 255), -1)\n",
    "            cv2.putText(corner_frame, f\"Corner {i+1}\", (corner[0]+10, corner[1]), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imwrite(\"detected_corners.jpg\", corner_frame)\n",
    "        \n",
    "        return corners\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating intersections: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee1404e-1e0c-428a-8469-4423d1a7c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_intersection(line1, line2):\n",
    "    \"\"\"Find the intersection point of two lines\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    \n",
    "    # Line 1 represented as a1x + b1y = c1\n",
    "    a1 = y2 - y1\n",
    "    b1 = x1 - x2\n",
    "    c1 = a1 * x1 + b1 * y1\n",
    "    \n",
    "    # Line 2 represented as a2x + b2y = c2\n",
    "    a2 = y4 - y3\n",
    "    b2 = x3 - x4\n",
    "    c2 = a2 * x3 + b2 * y3\n",
    "    \n",
    "    determinant = a1 * b2 - a2 * b1\n",
    "    \n",
    "    if determinant == 0:\n",
    "        # Lines are parallel\n",
    "        raise Exception(\"Lines are parallel, no intersection\")\n",
    "    else:\n",
    "        x = (b2 * c1 - b1 * c2) / determinant\n",
    "        y = (a1 * c2 - a2 * c1) / determinant\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c328c5-7ec4-4622-95aa-f846d4932d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_court_selection_with_guidance(frame):\n",
    "    \"\"\"\n",
    "    Allow manual selection of court corners with guidance images\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            corners.append((x, y))\n",
    "            # Draw circle at selected point\n",
    "            cv2.circle(display_frame, (x, y), 10, (0, 0, 255), -1)\n",
    "            \n",
    "            # Label the point\n",
    "            point_label = [\"Top-Left\", \"Top-Right\", \"Bottom-Right\", \"Bottom-Left\"][len(corners) - 1]\n",
    "            cv2.putText(display_frame, point_label, (x+10, y), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Select Court Corners', display_frame)\n",
    "            \n",
    "            if len(corners) == 4:\n",
    "                cv2.waitKey(1000)  # Wait a bit to show the final point\n",
    "                cv2.destroyWindow('Select Court Corners')\n",
    "    \n",
    "    # Create a copy of the frame for display with guidance overlay\n",
    "    display_frame = frame.copy()\n",
    "    \n",
    "    # Add guidance overlay - court diagram\n",
    "    h, w = frame.shape[:2]\n",
    "    overlay_margin = int(h * 0.1)\n",
    "    overlay_size = (int(w * 0.25), int(h * 0.25))\n",
    "    \n",
    "    # Create a simple court diagram\n",
    "    court_diagram = np.ones((overlay_size[1], overlay_size[0], 3), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(court_diagram, (5, 5), (overlay_size[0]-5, overlay_size[1]-5), (0, 0, 0), 2)\n",
    "    cv2.line(court_diagram, (5, overlay_size[1]//2), (overlay_size[0]-5, overlay_size[1]//2), (0, 0, 0), 2)\n",
    "    \n",
    "    # Add corner labels\n",
    "    cv2.putText(court_diagram, \"1\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.putText(court_diagram, \"2\", (overlay_size[0]-20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.putText(court_diagram, \"3\", (overlay_size[0]-20, overlay_size[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.putText(court_diagram, \"4\", (10, overlay_size[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "    # Place the diagram in the corner of the display frame\n",
    "    display_frame[overlay_margin:overlay_margin+overlay_size[1], \n",
    "                 overlay_margin:overlay_margin+overlay_size[0]] = court_diagram\n",
    "    \n",
    "    # Display instructions\n",
    "    instruction_text = [\n",
    "        \"Select 4 court corners in this order:\",\n",
    "        \"1: Top-Left (net side)\",\n",
    "        \"2: Top-Right (net side)\", \n",
    "        \"3: Bottom-Right (back of court)\",\n",
    "        \"4: Bottom-Left (back of court)\"\n",
    "    ]\n",
    "    \n",
    "    y_pos = overlay_margin + overlay_size[1] + 30\n",
    "    for i, line in enumerate(instruction_text):\n",
    "        cv2.putText(display_frame, line, (overlay_margin, y_pos + i*30), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.namedWindow('Select Court Corners')\n",
    "    cv2.setMouseCallback('Select Court Corners', mouse_callback)\n",
    "    cv2.imshow('Select Court Corners', display_frame)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    return corners if len(corners) == 4 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c632fe0-761c-44b8-9167-9f4438f62e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(frame, corners, target_width=800, target_height=400):\n",
    "    \"\"\"\n",
    "    Apply perspective transformation to get a top-down view of the court\n",
    "    \"\"\"\n",
    "    # Define the destination points (rectangle)\n",
    "    dst_points = np.array([\n",
    "        [0, 0],                       # Top-left\n",
    "        [target_width, 0],            # Top-right\n",
    "        [target_width, target_height],  # Bottom-right\n",
    "        [0, target_height]            # Bottom-left\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Convert corners to numpy array\n",
    "    src_points = np.array(corners, dtype=np.float32)\n",
    "    \n",
    "    # Compute perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    \n",
    "    # Apply transformation\n",
    "    warped = cv2.warpPerspective(frame, M, (target_width, target_height))\n",
    "    \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8cf9216-9224-45f2-a5b5-6cc2991dcd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_improved_perspective(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process a video to detect court using improved methods and transform perspective\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Read first frame for court detection\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Try automatic court detection with improved method\n",
    "    print(\"Attempting automatic court detection...\")\n",
    "    corners = detect_specific_court_lines(first_frame)\n",
    "    \n",
    "    # If automatic detection fails, use guided manual selection\n",
    "    if corners is None or len(corners) != 4:\n",
    "        print(\"Automatic court detection failed. Please select court corners manually.\")\n",
    "        corners = manual_court_selection_with_guidance(first_frame)\n",
    "        \n",
    "        if corners is None or len(corners) != 4:\n",
    "            print(\"Court corner selection failed\")\n",
    "            return False\n",
    "    \n",
    "    # Apply perspective transform\n",
    "    target_width, target_height = 800, 400  # Standard padel court dimensions (scaled)\n",
    "    warped_first_frame, perspective_matrix = apply_perspective_transform(\n",
    "        first_frame, corners, target_width, target_height\n",
    "    )\n",
    "    \n",
    "    # Save the first transformed frame for verification\n",
    "    cv2.imwrite(\"first_frame_transformed.jpg\", warped_first_frame)\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (target_width, target_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply perspective transform\n",
    "            warped_frame, _ = apply_perspective_transform(\n",
    "                frame, corners, target_width, target_height\n",
    "            )\n",
    "            \n",
    "            # Write transformed frame\n",
    "            out.write(warped_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Perspective-corrected video saved to {output_path}\")\n",
    "    \n",
    "    # Save the perspective matrix for future use in player tracking\n",
    "    np.save(\"perspective_matrix.npy\", perspective_matrix)\n",
    "    print(\"Perspective transformation matrix saved to perspective_matrix.npy\")\n",
    "    \n",
    "    return True, perspective_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0c19d0-6138-4a42-ac46-e8bc742dc31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting automatic court detection...\n",
      "Not enough lines detected, try using manual selection\n",
      "Automatic court detection failed. Please select court corners manually.\n",
      "Processing video with 301 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▊| 300/301 [00:02<00:00, 127.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perspective-corrected video saved to v2.mp4\n",
      "Perspective transformation matrix saved to perspective_matrix.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success, transform_matrix = process_video_with_improved_perspective(\"10secs.mp4\", \"v2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98575f43-9ad1-4424-b3a5-f91e47e92d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env5",
   "language": "python",
   "name": "env5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
