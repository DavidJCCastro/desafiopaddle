{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ae9ede-8149-4e1b-89f5-4f22ad94d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcd4dd1-b0c5-4762-acc9-456404120ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_video(input_path, output_path, calibration_images=None):\n",
    "    \"\"\"\n",
    "    Remove lens distortion from a video file\n",
    "    \n",
    "    Parameters:\n",
    "    - input_path: Path to the input video file\n",
    "    - output_path: Path to save the undistorted video\n",
    "    - calibration_images: Optional list of paths to chessboard images for calibration\n",
    "                         If None, uses default estimation values\n",
    "    \"\"\"\n",
    "    # Use estimated values for a typical wide-angle camera\n",
    "    # These are default values, adjust based on your specific camera if known\n",
    "    print(\"Using default camera parameters (no calibration images provided)\")\n",
    "    # Camera matrix (focal length and optical centers)\n",
    "    mtx = np.array([\n",
    "        [1000, 0, 960],  # fx, 0, cx\n",
    "        [0, 1000, 540],  # 0, fy, cy\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist = np.array([[-0.3, 0.1, 0, 0, -0.02]])\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate optimal camera matrix\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (width, height), 1, (width, height))\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    frame_idx = 0\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Undistort the frame\n",
    "            dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "            \n",
    "            # Crop the image (optional)\n",
    "            x, y, w, h = roi\n",
    "            dst = dst[y:y+h, x:x+w]\n",
    "            \n",
    "            # Resize back to original dimensions if needed\n",
    "            if dst.shape[1] != width or dst.shape[0] != height:\n",
    "                dst = cv2.resize(dst, (width, height))\n",
    "            \n",
    "            # Write the undistorted frame\n",
    "            out.write(dst)\n",
    "            \n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Undistorted video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcb42d4-8cb1-4aa8-9ba8-657efb03e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default camera parameters (no calibration images provided)\n",
      "Processing video with 301 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████▊| 300/301 [00:04<00:00, 60.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undistorted video saved to undist.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undistort_video(\"10secs.mp4\", \"undist.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc8856c1-5220-403f-8903-282b911ec279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_court_lines(frame):\n",
    "    \"\"\"\n",
    "    Detect court lines using Hough Line Transform\n",
    "    Returns the court corners if found\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Use adaptive thresholding to identify court lines\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "    \n",
    "    # Find edges\n",
    "    edges = cv2.Canny(thresh, 50, 150)\n",
    "    \n",
    "    # Dilate to connect edge components\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Find lines using HoughLinesP\n",
    "    lines = cv2.HoughLinesP(\n",
    "        dilated, 1, np.pi/180, threshold=50, \n",
    "        minLineLength=50, maxLineGap=10\n",
    "    )\n",
    "    \n",
    "    if lines is None:\n",
    "        return None\n",
    "    \n",
    "    # Draw lines on a copy of the frame for visualization\n",
    "    line_frame = frame.copy()\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # For debugging: save the line detection result\n",
    "    cv2.imwrite(\"court_lines_detected.jpg\", line_frame)\n",
    "    \n",
    "    # Group lines into horizontal and vertical\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Calculate angle\n",
    "        angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "        \n",
    "        # Group based on angle\n",
    "        if angle < 45 or angle > 135:  # Horizontal lines\n",
    "            h_lines.append(line[0])\n",
    "        else:  # Vertical lines\n",
    "            v_lines.append(line[0])\n",
    "    \n",
    "    # If we don't have enough lines, return None\n",
    "    if len(h_lines) < 2 or len(v_lines) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Find boundary lines (furthest lines in each direction)\n",
    "    h_lines = sorted(h_lines, key=lambda line: (line[1] + line[3]) / 2)  # Sort by y-coordinate\n",
    "    v_lines = sorted(v_lines, key=lambda line: (line[0] + line[2]) / 2)  # Sort by x-coordinate\n",
    "    \n",
    "    top_line = h_lines[0]\n",
    "    bottom_line = h_lines[-1]\n",
    "    left_line = v_lines[0]\n",
    "    right_line = v_lines[-1]\n",
    "    \n",
    "    # Find intersections of these lines to get court corners\n",
    "    top_left = line_intersection(top_line, left_line)\n",
    "    top_right = line_intersection(top_line, right_line)\n",
    "    bottom_left = line_intersection(bottom_line, left_line)\n",
    "    bottom_right = line_intersection(bottom_line, right_line)\n",
    "    \n",
    "    # Convert to integer points\n",
    "    corners = [\n",
    "        (int(top_left[0]), int(top_left[1])),\n",
    "        (int(top_right[0]), int(top_right[1])),\n",
    "        (int(bottom_right[0]), int(bottom_right[1])),\n",
    "        (int(bottom_left[0]), int(bottom_left[1]))\n",
    "    ]\n",
    "    \n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fa474c-ffe0-4745-bcaa-3a4c0d4cdbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_intersection(line1, line2):\n",
    "    \"\"\"Find the intersection point of two lines\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    \n",
    "    # Line 1 represented as a1x + b1y = c1\n",
    "    a1 = y2 - y1\n",
    "    b1 = x1 - x2\n",
    "    c1 = a1 * x1 + b1 * y1\n",
    "    \n",
    "    # Line 2 represented as a2x + b2y = c2\n",
    "    a2 = y4 - y3\n",
    "    b2 = x3 - x4\n",
    "    c2 = a2 * x3 + b2 * y3\n",
    "    \n",
    "    determinant = a1 * b2 - a2 * b1\n",
    "    \n",
    "    if determinant == 0:\n",
    "        # Lines are parallel\n",
    "        return (0, 0)\n",
    "    else:\n",
    "        x = (b2 * c1 - b1 * c2) / determinant\n",
    "        y = (a1 * c2 - a2 * c1) / determinant\n",
    "        return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e88198-1da3-4a94-9466-3acb5e47a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_court_selection(frame):\n",
    "    \"\"\"\n",
    "    Allow manual selection of court corners if automatic detection fails\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            corners.append((x, y))\n",
    "            # Draw circle at selected point\n",
    "            cv2.circle(display_frame, (x, y), 5, (0, 255, 0), -1)\n",
    "            cv2.imshow('Select Court Corners', display_frame)\n",
    "            \n",
    "            if len(corners) == 4:\n",
    "                cv2.destroyWindow('Select Court Corners')\n",
    "    \n",
    "    # Create a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "    cv2.namedWindow('Select Court Corners')\n",
    "    cv2.setMouseCallback('Select Court Corners', mouse_callback)\n",
    "    \n",
    "    # Display instructions\n",
    "    text = \"Click on 4 court corners in order: Top-Left, Top-Right, Bottom-Right, Bottom-Left\"\n",
    "    y_pos = 30\n",
    "    for i, line in enumerate(text.split(', ')):\n",
    "        cv2.putText(display_frame, line, (10, y_pos + i*30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Select Court Corners', display_frame)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    return corners if len(corners) == 4 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fca63f2-7b1a-4263-b63b-b46af443f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(frame, corners, target_width=800, target_height=400):\n",
    "    \"\"\"\n",
    "    Apply perspective transformation to get a top-down view of the court\n",
    "    \"\"\"\n",
    "    # Define the destination points (rectangle)\n",
    "    dst_points = np.array([\n",
    "        [0, 0],                      # Top-left\n",
    "        [target_width, 0],           # Top-right\n",
    "        [target_width, target_height], # Bottom-right\n",
    "        [0, target_height]           # Bottom-left\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Convert corners to numpy array\n",
    "    src_points = np.array(corners, dtype=np.float32)\n",
    "    \n",
    "    # Compute perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    \n",
    "    # Apply transformation\n",
    "    warped = cv2.warpPerspective(frame, M, (target_width, target_height))\n",
    "    \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a89556-c52c-45b3-b282-d132af813d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_perspective_transform(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process a video to detect court and transform perspective\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Read first frame for court detection\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Try automatic court detection\n",
    "    corners = detect_court_lines(first_frame)\n",
    "    \n",
    "    # If automatic detection fails, use manual selection\n",
    "    if corners is None or len(corners) != 4:\n",
    "        print(\"Automatic court detection failed. Please select court corners manually.\")\n",
    "        corners = manual_court_selection(first_frame)\n",
    "        \n",
    "        if corners is None or len(corners) != 4:\n",
    "            print(\"Court corner selection failed\")\n",
    "            return False\n",
    "    \n",
    "    # Apply perspective transform\n",
    "    target_width, target_height = 800, 400  # Standard padel court dimensions (scaled)\n",
    "    _, perspective_matrix = apply_perspective_transform(first_frame, corners, target_width, target_height)\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (target_width, target_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply perspective transform\n",
    "            warped_frame, _ = apply_perspective_transform(\n",
    "                frame, corners, target_width, target_height\n",
    "            )\n",
    "            \n",
    "            # Write transformed frame\n",
    "            out.write(warped_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Perspective-corrected video saved to {output_path}\")\n",
    "    \n",
    "    # Save the perspective matrix for future use in player tracking\n",
    "    np.save(\"perspective_matrix.npy\", perspective_matrix)\n",
    "    print(\"Perspective transformation matrix saved to perspective_matrix.npy\")\n",
    "    \n",
    "    return True, perspective_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c157970-de18-4d34-b36e-2b704dd7ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video with 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 300/300 [00:00<00:00, 353.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perspective-corrected video saved to new.mp4\n",
      "Perspective transformation matrix saved to perspective_matrix.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "succ, trans = process_video_with_perspective_transform(\"undist.mp4\", \"new.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6955183-45bf-4235-aea3-53c98ea8a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos_in_directory(input_dir, output_dir, calibration_dir=None):\n",
    "    \"\"\"\n",
    "    Process all .mp4 videos in a directory\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dir: Directory containing input videos \n",
    "    - output_dir: Directory to save processed videos\n",
    "    - calibration_dir: Optional directory with calibration images\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of calibration images if provided\n",
    "    calibration_images = None\n",
    "    if calibration_dir and os.path.exists(calibration_dir):\n",
    "        calibration_images = [os.path.join(calibration_dir, f) for f in os.listdir(calibration_dir)\n",
    "                             if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Process each video\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.mp4'):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f\"undistorted_{filename}\")\n",
    "            print(f\"Processing {filename}...\")\n",
    "            undistort_video(input_path, output_path, calibration_images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_video = \"paddle_game.mp4\"\n",
    "    output_video = \"undistorted_paddle_game.mp4\"\n",
    "    \n",
    "    # Option 1: Process a single video\n",
    "    undistort_video(input_video, output_video)\n",
    "    \n",
    "    # Option 2: Process all videos in a directory\n",
    "    # process_videos_in_directory(\"input_videos\", \"output_videos\", \"calibration_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env5",
   "language": "python",
   "name": "env5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
