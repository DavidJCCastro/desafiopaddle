{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca5e1da-7081-402a-93eb-f183d7439e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf10b8c-ed9e-4d03-a067-fb440a50568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/gigag/Documents/job/desafiopaddle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67c1e2-ba50-40ba-8251-e36ce42e9b6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Undistorting vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05c852-f1b5-4769-84f2-f4928a6a27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_video(input_path, output_path, calibration_images=None):\n",
    "    \"\"\"\n",
    "    Remove lens distortion from a video file\n",
    "    \n",
    "    Parameters:\n",
    "    - input_path: Path to the input video file\n",
    "    - output_path: Path to save the undistorted video\n",
    "    - calibration_images: Optional list of paths to chessboard images for calibration\n",
    "                         If None, uses default estimation values\n",
    "    \"\"\"\n",
    "    # Use estimated values for a typical wide-angle camera\n",
    "    # These are default values, adjust based on your specific camera if known\n",
    "    print(\"Using default camera parameters (no calibration images provided)\")\n",
    "    # Camera matrix (focal length and optical centers)\n",
    "    mtx = np.array([\n",
    "        [1000, 0, 960],  # fx, 0, cx\n",
    "        [0, 1000, 540],  # 0, fy, cy\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    # Distortion coefficients [k1, k2, p1, p2, k3]\n",
    "    dist = np.array([[-0.3, 0.1, 0, 0, -0.02]])\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate optimal camera matrix\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (width, height), 1, (width, height))\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    frame_idx = 0\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Undistort the frame\n",
    "            dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "            \n",
    "            # Crop the image (optional)\n",
    "            x, y, w, h = roi\n",
    "            dst = dst[y:y+h, x:x+w]\n",
    "            \n",
    "            # Resize back to original dimensions if needed\n",
    "            if dst.shape[1] != width or dst.shape[0] != height:\n",
    "                dst = cv2.resize(dst, (width, height))\n",
    "            \n",
    "            # Write the undistorted frame\n",
    "            out.write(dst)\n",
    "            \n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Undistorted video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786c87d-23b5-4ffe-8fe2-9771c1e7be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "undistort_video(\"10secs.mp4\", \"undist.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cdaed-8cb2-475b-ac70-f37acc7367ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Rotating to straighten the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ccb090-e4d7-4140-8671-c84404173956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_court_lines_for_alignment(frame):\n",
    "    \"\"\"\n",
    "    Detect main court lines just for alignment purposes\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Dilate to connect edge components\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Save intermediate results for debugging\n",
    "    cv2.imwrite(\"edges_detected.jpg\", edges)\n",
    "    \n",
    "    # Detect lines using Hough Line Transform\n",
    "    lines = cv2.HoughLinesP(\n",
    "        dilated, rho=1, theta=np.pi/180, \n",
    "        threshold=100, minLineLength=100, maxLineGap=10\n",
    "    )\n",
    "    \n",
    "    if lines is None or len(lines) < 3:\n",
    "        print(\"Not enough lines detected, try lower thresholds\")\n",
    "        return None\n",
    "    \n",
    "    # Find horizontal-ish lines (court boundaries)\n",
    "    h_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Calculate angle and length\n",
    "        angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        \n",
    "        # Group based on angle (horizontal-ish lines)\n",
    "        if angle < 30 or angle > 150:\n",
    "            h_lines.append((line[0], length, angle))\n",
    "    \n",
    "    # Sort by length to get the most prominent lines\n",
    "    h_lines.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the longest horizontal line for angle calculation\n",
    "    if h_lines:\n",
    "        main_line = h_lines[0][0]\n",
    "        x1, y1, x2, y2 = main_line\n",
    "        \n",
    "        # Calculate angle of rotation needed\n",
    "        angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "        if angle > 90:\n",
    "            angle = angle - 180\n",
    "        \n",
    "        # Visualization for debugging\n",
    "        line_frame = frame.copy()\n",
    "        cv2.line(line_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        cv2.putText(line_frame, f\"Angle: {angle:.2f} degrees\", (50, 50), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imwrite(\"main_alignment_line.jpg\", line_frame)\n",
    "        \n",
    "        return angle\n",
    "    else:\n",
    "        print(\"No suitable horizontal lines found\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595be15e-e25e-472b-aec4-00feab8fa6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_center_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Align the court to be level and center it in the frame\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video dimensions: {width}x{height}, FPS: {fps}\")\n",
    "    \n",
    "    # Read first frame for court detection\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Try to detect court angle\n",
    "    print(\"Detecting court alignment...\")\n",
    "    angle = detect_court_lines_for_alignment(first_frame)\n",
    "    \n",
    "    if angle is None:\n",
    "        print(\"Could not detect court angle automatically.\")\n",
    "        # Default to no rotation\n",
    "        angle = 0\n",
    "    \n",
    "    print(f\"Detected rotation angle: {angle:.2f} degrees\")\n",
    "    \n",
    "    # Calculate transformation matrix for rotation\n",
    "    # Get rotation matrix for the angle\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate new dimensions after rotation to avoid cropping\n",
    "    abs_cos = abs(rotation_matrix[0, 0])\n",
    "    abs_sin = abs(rotation_matrix[0, 1])\n",
    "    new_width = int(height * abs_sin + width * abs_cos)\n",
    "    new_height = int(height * abs_cos + width * abs_sin)\n",
    "    \n",
    "    # Adjust the rotation matrix to take into account the new dimensions\n",
    "    rotation_matrix[0, 2] += (new_width - width) // 2\n",
    "    rotation_matrix[1, 2] += (new_height - height) // 2\n",
    "    \n",
    "    # Apply rotation to the first frame for verification\n",
    "    rotated_first_frame = cv2.warpAffine(first_frame, rotation_matrix, (new_width, new_height))\n",
    "    cv2.imwrite(\"rotated_first_frame.jpg\", rotated_first_frame)\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply rotation\n",
    "            rotated_frame = cv2.warpAffine(frame, rotation_matrix, (new_width, new_height))\n",
    "            \n",
    "            # Write rotated frame\n",
    "            out.write(rotated_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Aligned video saved to {output_path}\")\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4176e234-0f77-4a2c-8b6d-cd3996e2b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_rotate_and_center(input_path, output_path, angle=0):\n",
    "    \"\"\"\n",
    "    Manually rotate and center the video by a specified angle\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video dimensions: {width}x{height}, FPS: {fps}\")\n",
    "    \n",
    "    # Read first frame for preview\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Calculate transformation matrix for rotation\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate new dimensions after rotation to avoid cropping\n",
    "    abs_cos = abs(rotation_matrix[0, 0])\n",
    "    abs_sin = abs(rotation_matrix[0, 1])\n",
    "    new_width = int(height * abs_sin + width * abs_cos)\n",
    "    new_height = int(height * abs_cos + width * abs_sin)\n",
    "    \n",
    "    # Adjust the rotation matrix to take into account the new dimensions\n",
    "    rotation_matrix[0, 2] += (new_width - width) // 2\n",
    "    rotation_matrix[1, 2] += (new_height - height) // 2\n",
    "    \n",
    "    # Apply rotation to the first frame for verification\n",
    "    rotated_first_frame = cv2.warpAffine(first_frame, rotation_matrix, (new_width, new_height))\n",
    "    cv2.imwrite(\"manual_rotated_preview.jpg\", rotated_first_frame)\n",
    "    \n",
    "    print(f\"Preview saved with {angle} degree rotation. Check 'manual_rotated_preview.jpg'\")\n",
    "    print(\"If you're satisfied with the rotation, proceed. Otherwise, try a different angle value.\")\n",
    "    \n",
    "    # Ask for confirmation - you can remove this part if running in a script\n",
    "    proceed = input(\"Proceed with processing the whole video? (y/n): \")\n",
    "    if proceed.lower() != 'y':\n",
    "        return False\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply rotation\n",
    "            rotated_frame = cv2.warpAffine(frame, rotation_matrix, (new_width, new_height))\n",
    "            \n",
    "            # Write rotated frame\n",
    "            out.write(rotated_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Aligned video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfb616d-4d0e-4dca-af7d-99712a21539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rotation_preview(input_path, angles=[-2, -1, 0, 1, 2]):\n",
    "    \"\"\"\n",
    "    Generate preview images with different rotation angles\n",
    "    \"\"\"\n",
    "    # Read the first frame\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    \n",
    "    for angle in angles:\n",
    "        # Get rotation matrix\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        \n",
    "        # Calculate new dimensions after rotation to avoid cropping\n",
    "        abs_cos = abs(rotation_matrix[0, 0])\n",
    "        abs_sin = abs(rotation_matrix[0, 1])\n",
    "        new_width = int(height * abs_sin + width * abs_cos)\n",
    "        new_height = int(height * abs_cos + width * abs_sin)\n",
    "        \n",
    "        # Adjust the rotation matrix to take into account the new dimensions\n",
    "        rotation_matrix[0, 2] += (new_width - width) // 2\n",
    "        rotation_matrix[1, 2] += (new_height - height) // 2\n",
    "        \n",
    "        # Apply rotation to the frame\n",
    "        rotated_frame = cv2.warpAffine(frame, rotation_matrix, (new_width, new_height))\n",
    "        \n",
    "        # Add text to indicate the angle\n",
    "        cv2.putText(rotated_frame, f\"Rotation: {angle} degrees\", (50, 50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # Save the preview image\n",
    "        preview_path = f\"rotation_preview_{angle}.jpg\"\n",
    "        cv2.imwrite(preview_path, rotated_frame)\n",
    "        print(f\"Saved preview for {angle} degrees rotation to {preview_path}\")\n",
    "    \n",
    "    print(\"Generated preview images for different rotation angles.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65552277-197a-444c-9718-7d5ab736e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 30.1\n",
      "Detecting court alignment...\n",
      "Detected rotation angle: -0.95 degrees\n",
      "Processing video with 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [00:06<00:00, 48.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned video saved to v3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_and_center_video(\"undist.mp4\", \"v3.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314051e2-2fa7-4ffe-bd91-5cc19eafe914",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6996e711-24bf-46d8-b456-9f8f1cbde77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_court_alignment_improved(frame):\n",
    "    \"\"\"\n",
    "    Improved method to detect court alignment angle\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection with lower threshold to catch more lines\n",
    "    edges = cv2.Canny(blurred, 40, 120)\n",
    "    \n",
    "    # Dilate to connect edge components\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Save intermediate results for debugging\n",
    "    cv2.imwrite(\"edges_detected.jpg\", edges)\n",
    "    \n",
    "    # Detect lines using Hough Lines Transform (not HoughLinesP)\n",
    "    # This gives us more precise angle measurements\n",
    "    lines = cv2.HoughLines(dilated, rho=1, theta=np.pi/180, threshold=150)\n",
    "    \n",
    "    if lines is None or len(lines) < 5:  # Need multiple lines for consensus\n",
    "        # Fall back to HoughLinesP if needed\n",
    "        print(\"Few lines detected with HoughLines, trying HoughLinesP...\")\n",
    "        lines_p = cv2.HoughLinesP(\n",
    "            dilated, rho=1, theta=np.pi/180, \n",
    "            threshold=80, minLineLength=80, maxLineGap=15\n",
    "        )\n",
    "        \n",
    "        if lines_p is None or len(lines_p) < 3:\n",
    "            print(\"Not enough lines detected with either method\")\n",
    "            return None\n",
    "            \n",
    "        # Convert HoughLinesP format to angles only\n",
    "        angles = []\n",
    "        for line in lines_p:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # Only consider relatively horizontal lines\n",
    "            curr_angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "            if abs(curr_angle) < 45 or abs(curr_angle) > 135:\n",
    "                angles.append(curr_angle)\n",
    "                \n",
    "        if not angles:\n",
    "            print(\"No suitable horizontal lines found\")\n",
    "            return None\n",
    "    else:\n",
    "        # Process HoughLines output (rho, theta format)\n",
    "        angles = []\n",
    "        for rho, theta in lines[:, 0]:\n",
    "            # Convert theta to degrees\n",
    "            angle_rad = theta\n",
    "            angle_deg = angle_rad * 180 / np.pi - 90  # -90 to get the actual line angle\n",
    "            \n",
    "            # Only consider relatively horizontal lines (near 0 or 180 degrees)\n",
    "            if abs(angle_deg) < 45 or abs(angle_deg - 180) < 45 or abs(angle_deg + 180) < 45:\n",
    "                # Normalize angle to -90 to +90 range\n",
    "                if angle_deg > 90:\n",
    "                    angle_deg -= 180\n",
    "                elif angle_deg < -90:\n",
    "                    angle_deg += 180\n",
    "                    \n",
    "                angles.append(angle_deg)\n",
    "    \n",
    "    # Create a visualization of all detected lines\n",
    "    debug_frame = frame.copy()\n",
    "    \n",
    "    if lines is not None:\n",
    "        for rho, theta in lines[:, 0]:\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000*(-b))\n",
    "            y1 = int(y0 + 1000*(a))\n",
    "            x2 = int(x0 - 1000*(-b))\n",
    "            y2 = int(y0 - 1000*(a))\n",
    "            cv2.line(debug_frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    \n",
    "    cv2.imwrite(\"all_detected_lines.jpg\", debug_frame)\n",
    "    \n",
    "    # Use statistical approach to find the consensus angle\n",
    "    if not angles:\n",
    "        print(\"No suitable lines found for angle calculation\")\n",
    "        return None\n",
    "    \n",
    "    # Create a histogram of angles to find the most common alignment\n",
    "    # This is more robust than just taking the average\n",
    "    hist, bin_edges = np.histogram(angles, bins=36, range=(-45, 45))\n",
    "    most_common_bin = np.argmax(hist)\n",
    "    \n",
    "    # Calculate the average angle within the most common bin\n",
    "    bin_min = bin_edges[most_common_bin]\n",
    "    bin_max = bin_edges[most_common_bin + 1]\n",
    "    filtered_angles = [a for a in angles if bin_min <= a <= bin_max]\n",
    "    \n",
    "    # Remove outliers using IQR method for more robustness\n",
    "    if filtered_angles:\n",
    "        q1 = np.percentile(filtered_angles, 25)\n",
    "        q3 = np.percentile(filtered_angles, 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        final_angles = [a for a in filtered_angles if lower_bound <= a <= upper_bound]\n",
    "        \n",
    "        if not final_angles:\n",
    "            final_angles = filtered_angles  # Fallback\n",
    "            \n",
    "        final_angle = np.median(final_angles)  # Median is more robust than mean\n",
    "    else:\n",
    "        final_angle = np.median(angles)  # Fallback\n",
    "    \n",
    "    # Create visualization of the chosen angle\n",
    "    angle_vis_frame = frame.copy()\n",
    "    h, w = frame.shape[:2]\n",
    "    center_x, center_y = w // 2, h // 2\n",
    "    length = max(w, h) // 2\n",
    "    \n",
    "    end_x = int(center_x + length * np.cos(final_angle * np.pi / 180))\n",
    "    end_y = int(center_y + length * np.sin(final_angle * np.pi / 180))\n",
    "    \n",
    "    cv2.line(angle_vis_frame, (center_x, center_y), (end_x, end_y), (0, 0, 255), 3)\n",
    "    cv2.putText(angle_vis_frame, f\"Angle: {final_angle:.2f}°\", \n",
    "              (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imwrite(\"final_alignment_angle.jpg\", angle_vis_frame)\n",
    "    \n",
    "    return final_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958d287c-0377-4d45-b011-0d423af0df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_court_video_improved(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Align the court video using improved detection method\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video dimensions: {width}x{height}, FPS: {fps}\")\n",
    "    \n",
    "    # Process multiple frames for more robust detection\n",
    "    num_sample_frames = 5\n",
    "    frame_indices = np.linspace(0, min(frame_count-1, 100), num_sample_frames, dtype=int)\n",
    "    \n",
    "    angles = []\n",
    "    \n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "            \n",
    "        angle = detect_court_alignment_improved(frame)\n",
    "        if angle is not None:\n",
    "            angles.append(angle)\n",
    "            print(f\"Frame {idx}: Detected angle {angle:.2f} degrees\")\n",
    "    \n",
    "    if not angles:\n",
    "        print(\"Could not detect court angle from any sample frame\")\n",
    "        return False\n",
    "    \n",
    "    # Use median angle for robustness\n",
    "    final_angle = np.median(angles)\n",
    "    print(f\"Final rotation angle: {final_angle:.2f} degrees (median of {len(angles)} estimates)\")\n",
    "    \n",
    "    # Calculate transformation matrix for rotation\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, final_angle, 1.0)\n",
    "    \n",
    "    # Calculate new dimensions after rotation to avoid cropping\n",
    "    abs_cos = abs(rotation_matrix[0, 0])\n",
    "    abs_sin = abs(rotation_matrix[0, 1])\n",
    "    new_width = int(height * abs_sin + width * abs_cos)\n",
    "    new_height = int(height * abs_cos + width * abs_sin)\n",
    "    \n",
    "    # Adjust the rotation matrix to take into account the new dimensions\n",
    "    rotation_matrix[0, 2] += (new_width - width) // 2\n",
    "    rotation_matrix[1, 2] += (new_height - height) // 2\n",
    "    \n",
    "    # Reset video capture to beginning and prepare output\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    # Process each frame\n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply rotation\n",
    "            rotated_frame = cv2.warpAffine(frame, rotation_matrix, (new_width, new_height))\n",
    "            \n",
    "            # Write rotated frame\n",
    "            out.write(rotated_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Aligned video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae39fc30-4b8c-47c3-8d05-d64f1241ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 1920x1080, FPS: 30.1\n",
      "Frame 0: Detected angle 41.00 degrees\n",
      "Frame 25: Detected angle 41.00 degrees\n",
      "Frame 50: Detected angle 41.00 degrees\n",
      "Frame 75: Detected angle 41.00 degrees\n",
      "Frame 100: Detected angle 41.00 degrees\n",
      "Final rotation angle: 41.00 degrees (median of 5 estimates)\n",
      "Processing video with 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [00:10<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned video saved to v5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_court_video_improved(\"undist.mp4\", \"v5.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5129f6-8e8e-4284-8e52-a3cd679b675f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Best result so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0887461-3317-4210-8eaf-926c99ac65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_court_lines_for_alignment(frame):\n",
    "    \"\"\"\n",
    "    Detect main court lines using thresholding instead of edge detection\n",
    "    \"\"\"\n",
    "    # Convert to HSV for better color segmentation\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create mask for white lines\n",
    "    # White in HSV has high V, low S, and any H\n",
    "    lower_white = np.array([0, 0, 180])\n",
    "    upper_white = np.array([180, 70, 255])\n",
    "    white_mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    \n",
    "    # Save the white mask for inspection\n",
    "    cv2.imwrite(\"white_mask.jpg\", white_mask)\n",
    "    \n",
    "    # Apply morphological operations to clean up the mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    white_mask_cleaned = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    white_mask_cleaned = cv2.morphologyEx(white_mask_cleaned, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    cv2.imwrite(\"white_mask_cleaned.jpg\", white_mask_cleaned)\n",
    "    \n",
    "    # Apply Hough Line Transform directly on the mask (preserves line width)\n",
    "    lines = cv2.HoughLinesP(\n",
    "        white_mask_cleaned, rho=1, theta=np.pi/180, \n",
    "        threshold=100, minLineLength=100, maxLineGap=20\n",
    "    )\n",
    "    \n",
    "    if lines is None or len(lines) < 3:\n",
    "        print(\"Not enough lines detected, trying with lower threshold...\")\n",
    "        # Try again with lower threshold\n",
    "        lines = cv2.HoughLinesP(\n",
    "            white_mask_cleaned, rho=1, theta=np.pi/180, \n",
    "            threshold=50, minLineLength=50, maxLineGap=30\n",
    "        )\n",
    "        \n",
    "        if lines is None or len(lines) < 3:\n",
    "            print(\"Still not enough lines detected\")\n",
    "            return None\n",
    "    \n",
    "    # Visualization of all detected lines\n",
    "    line_frame = frame.copy()\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(line_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imwrite(\"all_lines_detected.jpg\", line_frame)\n",
    "    \n",
    "    # Find horizontal-ish lines (court boundaries)\n",
    "    h_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Calculate angle and length\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        angle = np.abs(np.arctan2(dy, dx) * 180 / np.pi)\n",
    "        length = np.sqrt(dx*dx + dy*dy)\n",
    "        \n",
    "        # Group based on angle (horizontal-ish lines)\n",
    "        if angle < 30 or angle > 150:\n",
    "            h_lines.append((line[0], length, angle))\n",
    "    \n",
    "    # Sort by length to get the most prominent lines\n",
    "    h_lines.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the longest horizontal lines\n",
    "    longest_lines = h_lines[:min(3, len(h_lines))]\n",
    "    \n",
    "    # Calculate weighted average angle based on line length\n",
    "    if longest_lines:\n",
    "        total_weight = 0\n",
    "        weighted_angle_sum = 0\n",
    "        \n",
    "        for line_data, length, line_angle in longest_lines:\n",
    "            x1, y1, x2, y2 = line_data\n",
    "            # Calculate proper angle for rotation\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "            if angle > 90:\n",
    "                angle = angle - 180\n",
    "                \n",
    "            # Use length as weight\n",
    "            weighted_angle_sum += angle * length\n",
    "            total_weight += length\n",
    "            \n",
    "            # Visualization for debugging - show the lines used for angle calculation\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "        \n",
    "        # Weighted average angle\n",
    "        final_angle = weighted_angle_sum / total_weight\n",
    "        \n",
    "        # Add angle text to the visualization\n",
    "        cv2.putText(frame, f\"Angle: {final_angle:.2f} degrees\", (50, 50), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imwrite(\"main_alignment_lines.jpg\", frame)\n",
    "        \n",
    "        return final_angle\n",
    "    else:\n",
    "        print(\"No suitable horizontal lines found\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866654f4-c84d-4364-941b-fcc37f4d499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_center_video(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Align the court to be level and center it in the frame\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video dimensions: {width}x{height}, FPS: {fps}\")\n",
    "    \n",
    "    # Read first frame for court detection\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Try to detect court angle\n",
    "    print(\"Detecting court alignment...\")\n",
    "    angle = detect_court_lines_for_alignment(first_frame)\n",
    "    \n",
    "    if angle is None:\n",
    "        print(\"Could not detect court angle automatically.\")\n",
    "        # Default to no rotation\n",
    "        angle = 0\n",
    "    \n",
    "    print(f\"Detected rotation angle: {angle:.2f} degrees\")\n",
    "    \n",
    "    # Calculate transformation matrix for rotation\n",
    "    # Get rotation matrix for the angle\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate new dimensions after rotation to avoid cropping\n",
    "    abs_cos = abs(rotation_matrix[0, 0])\n",
    "    abs_sin = abs(rotation_matrix[0, 1])\n",
    "    new_width = int(height * abs_sin + width * abs_cos)\n",
    "    new_height = int(height * abs_cos + width * abs_sin)\n",
    "    \n",
    "    # Adjust the rotation matrix to take into account the new dimensions\n",
    "    rotation_matrix[0, 2] += (new_width - width) // 2\n",
    "    rotation_matrix[1, 2] += (new_height - height) // 2\n",
    "    \n",
    "    # Apply rotation to the first frame for verification\n",
    "    rotated_first_frame = cv2.warpAffine(first_frame, rotation_matrix, (new_width, new_height))\n",
    "    cv2.imwrite(\"rotated_first_frame.jpg\", rotated_first_frame)\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply rotation\n",
    "            rotated_frame = cv2.warpAffine(frame, rotation_matrix, (new_width, new_height))\n",
    "            \n",
    "            # Write rotated frame\n",
    "            out.write(rotated_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Aligned video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82130da5-d500-44c5-ad12-7ce03c468f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines_from_multiple_frames(input_path, num_frames=5):\n",
    "    \"\"\"\n",
    "    Detect court lines from multiple frames for more robust angle detection\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return None\n",
    "    \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate frame indices to sample evenly throughout the video\n",
    "    step = max(1, frame_count // (num_frames + 1))\n",
    "    frame_indices = [i * step for i in range(1, num_frames + 1)]\n",
    "    \n",
    "    angles = []\n",
    "    \n",
    "    for idx, frame_idx in enumerate(frame_indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(f\"Failed to read frame at index {frame_idx}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing frame {idx+1}/{len(frame_indices)} (frame index: {frame_idx})\")\n",
    "        \n",
    "        # Save the frame for reference\n",
    "        cv2.imwrite(f\"sample_frame_{idx+1}.jpg\", frame)\n",
    "        \n",
    "        # Detect angle\n",
    "        angle = detect_court_lines_for_alignment(frame)\n",
    "        \n",
    "        if angle is not None:\n",
    "            angles.append(angle)\n",
    "            print(f\"Frame {idx+1}: Detected angle = {angle:.2f} degrees\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if not angles:\n",
    "        print(\"Failed to detect any valid angles\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate median angle to avoid outliers\n",
    "    median_angle = np.median(angles)\n",
    "    print(f\"Angles detected: {angles}\")\n",
    "    print(f\"Median angle: {median_angle:.2f} degrees\")\n",
    "    \n",
    "    return median_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832eb2df-6da0-4b6e-90a3-ee7c1ad3591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_rotate_and_center(input_path, output_path, angle=0):\n",
    "    \"\"\"\n",
    "    Manually rotate and center the video by a specified angle\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Couldn't open video file {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video dimensions: {width}x{height}, FPS: {fps}\")\n",
    "    \n",
    "    # Read first frame for preview\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame\")\n",
    "        return False\n",
    "    \n",
    "    # Calculate transformation matrix for rotation\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Calculate new dimensions after rotation to avoid cropping\n",
    "    abs_cos = abs(rotation_matrix[0, 0])\n",
    "    abs_sin = abs(rotation_matrix[0, 1])\n",
    "    new_width = int(height * abs_sin + width * abs_cos)\n",
    "    new_height = int(height * abs_cos + width * abs_sin)\n",
    "    \n",
    "    # Adjust the rotation matrix to take into account the new dimensions\n",
    "    rotation_matrix[0, 2] += (new_width - width) // 2\n",
    "    rotation_matrix[1, 2] += (new_height - height) // 2\n",
    "    \n",
    "    # Apply rotation to the first frame for verification\n",
    "    rotated_first_frame = cv2.warpAffine(first_frame, rotation_matrix, (new_width, new_height))\n",
    "    cv2.imwrite(\"manual_rotated_preview.jpg\", rotated_first_frame)\n",
    "    \n",
    "    print(f\"Preview saved with {angle} degree rotation. Check 'manual_rotated_preview.jpg'\")\n",
    "    print(\"If you're satisfied with the rotation, proceed. Otherwise, try a different angle value.\")\n",
    "    \n",
    "    # Ask for confirmation - you can remove this interactive part if needed\n",
    "    proceed = input(\"Proceed with processing the whole video? (y/n): \")\n",
    "    if proceed.lower() != 'y':\n",
    "        return False\n",
    "    \n",
    "    # Create video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    # Reset video capture to beginning\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    print(f\"Processing video with {frame_count} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    with tqdm(total=frame_count) as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Apply rotation\n",
    "            rotated_frame = cv2.warpAffine(frame, rotation_matrix, (new_width, new_height))\n",
    "            \n",
    "            # Write rotated frame\n",
    "            out.write(rotated_frame)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Aligned video saved to {output_path}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b33f840-3924-4ce0-bc81-410ea74a93cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 1/5 (frame index: 50)\n",
      "Frame 1: Detected angle = -1.99 degrees\n",
      "Processing frame 2/5 (frame index: 100)\n",
      "Frame 2: Detected angle = -1.99 degrees\n",
      "Processing frame 3/5 (frame index: 150)\n",
      "Frame 3: Detected angle = -1.97 degrees\n",
      "Processing frame 4/5 (frame index: 200)\n",
      "Frame 4: Detected angle = -1.99 degrees\n",
      "Processing frame 5/5 (frame index: 250)\n",
      "Frame 5: Detected angle = -1.99 degrees\n",
      "Angles detected: [np.float64(-1.9932108826292696), np.float64(-1.9909618779330664), np.float64(-1.968076712069241), np.float64(-1.991809865891137), np.float64(-1.9945693012418506)]\n",
      "Median angle: -1.99 degrees\n",
      "Video dimensions: 1920x1080, FPS: 30.1\n",
      "Preview saved with -1.991809865891137 degree rotation. Check 'manual_rotated_preview.jpg'\n",
      "If you're satisfied with the rotation, proceed. Otherwise, try a different angle value.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Proceed with processing the whole video? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video with 300 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [00:06<00:00, 48.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned video saved to v1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_video = \"undist.mp4\"  # Use the output from previous distortion correction step\n",
    "output_video = \"v1.mp4\"\n",
    "\n",
    "\n",
    "angle = detect_lines_from_multiple_frames(input_video, num_frames=5)\n",
    "\n",
    "if angle is not None:\n",
    "    # Use the detected angle for alignment\n",
    "    manual_rotate_and_center(input_video, output_video, angle=angle)\n",
    "else:\n",
    "    print(\"Falling back to automatic alignment from a single frame\")\n",
    "    align_and_center_video(input_video, output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff37804",
   "metadata": {},
   "source": [
    "## Court homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec62620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f\"Clicked: ({x}, {y})\")\n",
    "        court_points.append((x, y))\n",
    "        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow(\"Select Court Corners\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample frame from your video\n",
    "VIDEO_PATH = \"v1.mp4\"\n",
    "FRAME_NUM = 1  # or any frame with a clear court view\n",
    "court_points = []\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, FRAME_NUM)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Failed to grab frame.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Click the 4 court corners in this order:\")\n",
    "print(\"1. Top-left, 2. Top-right, 3. Bottom-right, 4. Bottom-left\")\n",
    "\n",
    "cv2.imshow(\"Select Court Corners\", frame)\n",
    "cv2.setMouseCallback(\"Select Court Corners\", click_event)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Selected Points:\")\n",
    "for pt in court_points:\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save them for later use\n",
    "import numpy as np\n",
    "np.save(\"court_src_points.npy\", np.array(court_points, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911444da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard paddle court size mapped to pixels\n",
    "court_width = 800\n",
    "court_height = 400\n",
    "\n",
    "court_dst_points = np.array([\n",
    "    [0, 0],                      # Top-left\n",
    "    [court_width, 0],           # Top-right\n",
    "    [court_width, court_height],# Bottom-right\n",
    "    [0, court_height]           # Bottom-left\n",
    "], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78df39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "court_src_points = np.load(\"court_src_points.npy\")\n",
    "H = cv2.getPerspectiveTransform(court_src_points, court_dst_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_court(points, H):\n",
    "    points = np.array(points, dtype=np.float32).reshape(-1, 1, 2)\n",
    "    court_points = cv2.perspectiveTransform(points, H)\n",
    "    return court_points.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3b43f-8baf-4ae3-afe4-67755cc2095c",
   "metadata": {},
   "source": [
    "## Player tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce6dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from norfair import Detection, Tracker, Video, draw_tracked_objects\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742c2325-1448-4d7e-8351-eb46e99afe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ CONFIGURATION ------------\n",
    "VIDEO_PATH = \"v1.mp4\"\n",
    "OUTPUT_PATH = \"out.mp4\"\n",
    "YOLO_MODEL = \"yolov8n.pt\"  # use 'yolov8s.pt' for better accuracy\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "IOU_THRESHOLD = 0.4\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23348d80-4d53-411b-8b58-4899145600e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO\n",
    "model = YOLO(YOLO_MODEL)# Define distance function for Norfair\n",
    "def euclidean_distance(detection, tracked_object):\n",
    "    return np.linalg.norm(detection.points - tracked_object.estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b9692a-5c13-407b-8119-eaed0e723202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are using a scalar distance function. If you want to speed up the tracking process please consider using a vectorized distance function such as ['iou', 'iou_opt', 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'].\n"
     ]
    }
   ],
   "source": [
    "# Initialize tracker\n",
    "tracker = Tracker(distance_function=euclidean_distance, distance_threshold=30)\n",
    "\n",
    "# Open video input/output\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ca299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 3.8ms\n",
      "Speed: 2.2ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:draw_tracked_objects is deprecated, use draw_points instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.4ms\n",
      "Speed: 1.1ms preprocess, 4.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 1 skateboard, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.4ms\n",
      "Speed: 1.2ms preprocess, 4.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.4ms\n",
      "Speed: 1.1ms preprocess, 4.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4.5ms\n",
      "Speed: 1.1ms preprocess, 4.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.2ms preprocess, 4.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.3ms\n",
      "Speed: 1.2ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.9ms\n",
      "Speed: 1.3ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.2ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 tennis rackets, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 tennis rackets, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.3ms\n",
      "Speed: 1.2ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.4ms\n",
      "Speed: 1.0ms preprocess, 4.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 frisbee, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.2ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 skateboard, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.2ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.2ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.2ms\n",
      "Speed: 1.1ms preprocess, 4.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 1 baseball glove, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 tennis rackets, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tennis racket, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.2ms preprocess, 4.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 baseball glove, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3.7ms\n",
      "Speed: 1.1ms preprocess, 3.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 baseball glove, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "all_projected_points = []\n",
    "frame_num = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_num += 1\n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model(frame)[0]\n",
    "    detections = []\n",
    "    projected_positions = []\n",
    "    \n",
    "    for det in results.boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = det\n",
    "        if int(cls) != 0 or conf < CONFIDENCE_THRESHOLD:\n",
    "            continue  # Only keep 'person' class\n",
    "\n",
    "        cx = (x1 + x2) / 2\n",
    "        cy = (y1 + y2) / 2\n",
    "        detections.append(Detection(np.array([cx.item(), cy.item()])))\n",
    "        \n",
    "        # You have cx, cy (center of player bbox)\n",
    "        projected = project_to_court([(cx.item(), cy.item())], H)[0]\n",
    "        projected_positions.append(projected)\n",
    "\n",
    "    all_projected_points.append(projected_positions)\n",
    "\n",
    "    # Update tracker\n",
    "    tracked_objects = tracker.update(detections=detections)\n",
    "\n",
    "    # Draw tracked objects\n",
    "    draw_tracked_objects(frame, tracked_objects)\n",
    "\n",
    "    # Write frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # (Optional) Display\n",
    "    #cv2.imshow(\"Tracked\", frame)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132305c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af41082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Output saved to out.mp4\n"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Done. Output saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0804cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"all_projected_points.npy\", np.array(all_projected_points, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca3b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5360d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load projected player positions\n",
    "positions = np.load(\"all_projected_points.npy\", allow_pickle=True)\n",
    "\n",
    "# Flatten into a single list of (x, y)\n",
    "flat_positions = [pt for frame in positions for pt in frame]\n",
    "flat_positions = np.array(flat_positions)\n",
    "\n",
    "# Separate x and y for heatmap\n",
    "x = flat_positions[:, 0]\n",
    "y = flat_positions[:, 1]\n",
    "\n",
    "# Create heatmap using 2D histogram\n",
    "heatmap, xedges, yedges = np.histogram2d(x, y, bins=[80, 40], range=[[0, 800], [0, 400]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066230b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: smooth heatmap\n",
    "heatmap = np.rot90(heatmap)\n",
    "heatmap = np.flipud(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10763d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw0AAAHaCAYAAABCRaVeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgbBJREFUeJzt3XlcVFX/B/DPsA3IMiyyJpu4ICppLgiaoqJIPi7lo2kaaKZmqKHlo1QqLollmZmGy2Nmmlmae6m54b7gVpqpCO4CLsggICMx5/eHP+dxZGZkGZmLfN6v13294tx77vleJLjfOZtMCCFARERERESkh5mpAyAiIiIiImlj0kBERERERAYxaSAiIiIiIoOYNBARERERkUFMGoiIiIiIyCAmDUREREREZBCTBiIiIiIiMohJAxERERERGcSkgYiIiIiIDGLSQEQVkpycDJlMhuTkZFOHQkRERM8IkwYi0um7776DTCbTHNbW1qhXrx5GjBiBrKwsU4dnFI8SntWrV+s8P3DgQNjZ2T3TGA4cOICEhATk5OQ803aeF8XFxViyZAnCw8Ph7OwMuVwOPz8/DBo0CEePHjVZXNOnT8e6detM1j4R0bPGpIGIDJoyZQqWLVuGuXPnIiwsDElJSQgNDUVBQYGpQ3suHDhwAJMnT2bSUAr379/Hv/71L7z11lsQQuDDDz9EUlISoqOjcfDgQbRs2RLXrl0zSWxMGojoeWdh6gCISNqioqLQvHlzAMDbb78NFxcXzJo1C+vXr0e/fv1MHN3T5efnw9bW1tRhkBGMHTsWW7ZswZdffom4uDitc5MmTcKXX35ZqfEIIVBYWAgbG5tKbZeIyBTY00BEZdKhQwcAwMWLF/Ves3fvXvTu3Rs+Pj6Qy+Xw9vbG6NGjcf/+fc01S5YsgUwmw4kTJ0rUnz59OszNzXH9+nVN2eHDh9GlSxcoFArUqFED7dq1w/79+7XqJSQkQCaT4cyZM3jjjTfg5OSENm3aVPSRS9i8eTNefvll2Nrawt7eHl27dsVff/2ldc2ff/6JgQMHonbt2rC2toaHhwfeeust3LlzRyvesWPHAgD8/f01Q8EuXboEAJDJZBgxYgRWrVqFoKAg2NjYIDQ0FKdOnQIALFiwAHXq1IG1tTXCw8M19R4pzb8D8L9hWOnp6YiMjIStrS28vLwwZcoUCCFK9T355ptv0LBhQ8jlcnh5eSE2NrZE70l4eDgaNWqEM2fOoH379qhRowZeeOEFfPbZZ0+9/7Vr17BgwQJ06tSpRMIAAObm5vjggw9Qq1YtTdmJEycQFRUFBwcH2NnZoWPHjjh06JBWvUc/M096NDzv8e+pn58f/vWvf2Hr1q1o3rw5bGxssGDBAshkMuTn52Pp0qWaf8OBAwc+9ZmIiKoS9jQQUZmkpaUBAFxcXPRes2rVKhQUFGD48OFwcXHBkSNH8PXXX+PatWtYtWoVAODf//43YmNj8cMPP6Bp06Za9X/44QeEh4fjhRdeAADs3LkTUVFRaNasGSZNmgQzMzMsWbIEHTp0wN69e9GyZUut+r1790bdunUxffr0Ur303rt3D7dv3y5RrlKpSpQtW7YMMTExiIyMxKeffoqCggIkJSWhTZs2OHHiBPz8/AAA27ZtQ3p6OgYNGgQPDw/89ddfWLhwIf766y8cOnQIMpkMr732Gs6fP48ff/wRX375JWrWrAkAcHV11bS3d+9ebNiwAbGxsQCAxMRE/Otf/8J//vMffPPNN3j33Xdx9+5dfPbZZ3jrrbewc+fOMv07PFJcXIwuXbqgVatW+Oyzz7BlyxZMmjQJ//zzD6ZMmWLw+5eQkIDJkycjIiICw4cPx7lz55CUlISUlBTs378flpaWmmvv3r2LLl264LXXXkOfPn2wevVqjBs3Do0bN0ZUVJTeNjZv3ox//vkHb775psFYHvnrr7/w8ssvw8HBAf/5z39gaWmJBQsWIDw8HLt370ZISEip7vOkc+fOoV+/fhg2bBiGDBmC+vXrY9myZXj77bfRsmVLDB06FAAQEBBQrvsTEUmWICLSYcmSJQKA2L59u7h165a4evWqWLlypXBxcRE2Njbi2rVrQgghdu3aJQCIXbt2aeoWFBSUuF9iYqKQyWTi8uXLmrJ+/foJLy8vUVxcrCk7fvy4ACCWLFkihBBCrVaLunXrisjISKFWq7Xa8Pf3F506ddKUTZo0SQAQ/fr1K9UzPord0GFra6u5/t69e8LR0VEMGTJE6z6ZmZlCoVBolev6Hvz4448CgNizZ4+mbObMmQKAuHjxYonrAQi5XK51bsGCBQKA8PDwELm5uZry+Pj4Evcp7b9DTEyMACBGjhypKVOr1aJr167CyspK3Lp1q8R9Hrl586awsrISnTt31vp3nDt3rgAgvv32W01Zu3btBADx/fffa8pUKpXw8PAQvXr10tuGEEKMHj1aABAnTpwweN0jPXv2FFZWViItLU1TduPGDWFvby/atm2rKXv0M/OkRz//j38/fX19BQCxZcuWEtfb2tqKmJiYUsVGRFQVcXgSERkUEREBV1dXeHt7o2/fvrCzs8PatWs1vQC6PD7GOz8/H7dv30ZYWBiEEFrDkaKjo3Hjxg3s2rVLU/bDDz/AxsYGvXr1AgCcPHkSqampeOONN3Dnzh3cvn0bt2/fRn5+Pjp27Ig9e/ZArVZrtf/OO++U6RknTpyIbdu2lTg6d+6sdd22bduQk5ODfv36aeK4ffs2zM3NERISovUcj38PCgsLcfv2bbRq1QoAcPz48VLH1rFjR03vBQDNJ+S9evWCvb19ifL09HSdMRj6d3hkxIgRmv9+NDTqwYMH2L59u974tm/fjgcPHiAuLg5mZv/7kzJkyBA4ODjg119/1brezs4OAwYM0HxtZWWFli1basWtS25uLgBoPbM+xcXF+P3339GzZ0/Url1bU+7p6Yk33ngD+/bt09yvrPz9/REZGVmuukREVRmHJxGRQfPmzUO9evVgYWEBd3d31K9fX+vlUJcrV65g4sSJ2LBhA+7evat1TqlUav67U6dO8PT0xA8//ICOHTtCrVbjxx9/RI8ePTQvh6mpqQCAmJgYve0plUo4OTlpvvb39y/TMzZu3BgRERElypcvX6719aNYHs3reJKDg4Pmv7OzszF58mSsXLkSN2/eLBFvafn4+Gh9rVAoAADe3t46yx//fpf23wEAzMzMtF6wAaBevXoAUGKuxOMuX74MAKhfv75WuZWVFWrXrq05/0itWrVKzCFwcnLCn3/+qbcN4H/f23v37hm8DgBu3bqFgoKCEjEBQIMGDaBWq3H16lU0bNjwqfd6Ull/toiInhdMGojIoJYtW2pWTyqN4uJidOrUCdnZ2Rg3bhwCAwNha2uL69evY+DAgVq9Aubm5njjjTewaNEifPPNN9i/fz9u3Lih9Un0o+tnzpyJJk2a6Gzzyb0UntVqNo9iWbZsGTw8PEqct7D436/UPn364MCBAxg7diyaNGkCOzs7qNVqdOnSpUTPiCHm5uZlKhf/P4ejLP8OlelpcesTGBgIADh16pTen4Py0DUJGnj4/dOFKyURUXXFpIGIjOrUqVM4f/48li5diujoaE35tm3bdF4fHR2NL774Ahs3bsTmzZvh6uqqNfzj0YRSBwcHnb0BlelRLG5ubgZjuXv3Lnbs2IHJkydj4sSJmvJHPRWP0/fSWlFl/XdQq9VIT0/X9C4AwPnz5wFAa3jUk3x9fQE8nCD8eE/FgwcPcPHiRaP9m0VFRcHc3BzLly9/6mRoV1dX1KhRA+fOnStx7uzZszAzM9P01DzqocrJyYGjo6Pmuid7SJ7mWf07EhFJBec0EJFRPfok+fFPjoUQ+Oqrr3ReHxwcjODgYPz3v//FL7/8gr59+2p9Yt+sWTMEBATg888/R15eXon6t27dMvIT6BcZGQkHBwdMnz4dRUVFemPR9T0AgNmzZ5eo82gPCWNv7lbWfwcAmDt3rta1c+fOhaWlJTp27Ki3TkREBKysrDBnzhytthYvXgylUomuXbtW5DE0vL29MWTIEPz+++/4+uuvS5xXq9X44osvcO3aNZibm6Nz585Yv3691tCqrKwsrFixAm3atNEMd3qUCO7Zs0dz3aPlU8vC1taWG/QR0XONPQ1EZFSBgYEICAjABx98gOvXr8PBwQG//PJLiTH1j4uOjsYHH3wAAFpDk4CHY+3/+9//IioqCg0bNsSgQYPwwgsv4Pr169i1axccHBywcePGZ/pMjzg4OCApKQlvvvkmXnrpJfTt2xeurq64cuUKfv31V7Ru3Rpz586Fg4MD2rZti88++wxFRUV44YUX8Pvvv+vc26JZs2YAgI8++gh9+/aFpaUlunXrVuEN6cr672BtbY0tW7YgJiYGISEh2Lx5M3799Vd8+OGHWkvAPsnV1RXx8fGYPHkyunTpgu7du+PcuXP45ptv0KJFixL/nhXxxRdfIC0tDaNGjcKaNWvwr3/9C05OTrhy5QpWrVqFs2fPom/fvgCAadOmYdu2bWjTpg3effddWFhYYMGCBVCpVFr7QnTu3Bk+Pj4YPHgwxo4dC3Nzc3z77beaf9fSatasGbZv345Zs2bBy8sL/v7+5V7WlYhIkky0ahMRSdyjJSdTUlIMXqdrydUzZ86IiIgIYWdnJ2rWrCmGDBki/vjjD62lVB+XkZEhzM3NRb169fS2c+LECfHaa68JFxcXIZfLha+vr+jTp4/YsWOH5ppHy2caWiJUV+yrVq3SeT4mJkZrydXH60VGRgqFQiGsra1FQECAGDhwoDh69KjmmmvXrolXX31VODo6CoVCIXr37i1u3LghAIhJkyZp3W/q1KnihRdeEGZmZlrLfAIQsbGxWtdevHhRABAzZ8586rOU9t/h0XOmpaWJzp07ixo1agh3d3cxadIkrWVUDZk7d64IDAwUlpaWwt3dXQwfPlzcvXtX65p27dqJhg0blqgbExMjfH19S9XOP//8I/773/+Kl19+WSgUCmFpaSl8fX3FoEGDSizHevz4cREZGSns7OxEjRo1RPv27cWBAwdK3PPYsWMiJCREWFlZCR8fHzFr1iy9S6527dpVZ1xnz54Vbdu2FTY2NgIAl18loueOTIhSbvdJRPSM3L59G56enpg4cSImTJhg6nCqnYEDB2L16tU6h38REREBnNNARBLw3Xffobi4uNS7/RIREVHl4pwGIjKZnTt34syZM/jkk0/Qs2dPg6v0EBERkekwaSAik5kyZQoOHDiA1q1b61wRh4iIiKSBcxqIiIiIiMigKjGnYd68efDz84O1tTVCQkJw5MgRU4dERERERFRtSD5p+OmnnzBmzBhMmjQJx48fx4svvojIyEjcvHnT1KEREREREVULkh+eFBISghYtWmh2KlWr1fD29sbIkSMxfvx4E0dHRERERPT8k/RE6AcPHuDYsWOIj4/XlJmZmSEiIgIHDx4s9X3sZLJnER4RERERGUmetD/HrvYknTTcvn0bxcXFcHd31yp3d3fH2bNnddZRqVRQqVRaZQIA0wYiIiIiKp9/jHgvSb9+6yX5OQ1llZiYCIVCoXUUmTooIiIiIqIqTNJJQ82aNWFubo6srCyt8qysLHh4eOisEx8fD6VSqXVYVkawRERERPSc+seIR9Uk6aTBysoKzZo1w44dOzRlarUaO3bsQGhoqM46crkcDg4OWgeHJhERERFR+TFpkPygqjFjxiAmJgbNmzdHy5YtMXv2bOTn52PQoEGmDo2IiIiIqFqQfNLw+uuv49atW5g4cSIyMzPRpEkTbNmypcTkaCIiIiKiZ6Pq9hAYi+T3aTAGLrlKREREJG3SXnL1thHvVdOI96o8kp7TQEREREREpif54UlERERERKbF4UlMGoiIiIiIDGLSIPnhSUlJSQgODtYsnxoaGorNmzebOiwiIiIiompD8j0NtWrVwowZM1C3bl0IIbB06VL06NEDJ06cQMOGDU0dHhERERE999jTUCVXT3J2dsbMmTMxePDgUl3P1ZOIiIiIpE3aqyddMuK9/Ix4r8oj+Z6GxxUXF2PVqlXIz8/XuyM0EREREZFxFZs6AJOrEknDqVOnEBoaisLCQtjZ2WHt2rUICgoydVhEREREVC1weFKVSBrq16+PkydPQqlUYvXq1YiJicHu3bt1Jg4qlQoqlUqrTADgACUiIiIiovKpknMaIiIiEBAQgAULFpQ4l5CQgMmTJ2uVWQKwqqTYiIiIiKjspD2n4S8j3qtqLuQj+SVXdVGr1SV6Ex6Jj4+HUqnUOiwrOT4iIiIiep78Y8SjapL88KT4+HhERUXBx8cH9+7dw4oVK5CcnIytW7fqvF4ul0Mul2uVcWgSEREREVH5ST5puHnzJqKjo5GRkQGFQoHg4GBs3boVnTp1MnVoRERERFQtVN0eAmOpknMayor7NBARERFJm7TnNBw24r1CjHivylMl5zQQEREREVHlkfzwJCIiIiIi0+LwJCYNREREREQGMWng8CQiIiIiIjJI8knD9evXMWDAALi4uMDGxgaNGzfG0aNHTR0WEREREVUb3KdB0sOT7t69i9atW6N9+/bYvHkzXF1dkZqaCicnJ1OHRkRERETVRtV92TcWSScNn376Kby9vbFkyRJNmb+/vwkjIiIiIiKqfiQ9PGnDhg1o3rw5evfuDTc3NzRt2hSLFi0ydVhEREREVK1weJKkk4b09HQkJSWhbt262Lp1K4YPH45Ro0Zh6dKleuuoVCrk5uZqHVLeKoSIiIiIpI5Jg6R3hLayskLz5s1x4MABTdmoUaOQkpKCgwcP6qyTkJCAyZMna5VZArB6loESERERUYVIe0fo9Ua8Vw8j3qvySLqnwdPTE0FBQVplDRo0wJUrV/TWiY+Ph1Kp1Dosn3WgRERERPQcY0+DpCdCt27dGufOndMqO3/+PHx9ffXWkcvlkMvlWmWyZxIdEREREVUPVfdl31gk3dMwevRoHDp0CNOnT8eFCxewYsUKLFy4ELGxsaYOjYiIiIio2pD0nAYA2LRpE+Lj45Gamgp/f3+MGTMGQ4YMKdM97GTsayAiIiKSMmnPafjBiPfqb8R7VR7JJw3GwKSBiIiISNqknTToX7mz7GKMeK/KI+nhSUREREREZHqSnghNRERERGR6xaYOwOSYNBARERERGcTVkyQ/POnevXuIi4uDr68vbGxsEBYWhpSUFFOHRURERERUbUi+p+Htt9/G6dOnsWzZMnh5eWH58uWIiIjAmTNn8MILL5g6PCIiIiJ67rGnQdKrJ92/fx/29vZYv349unbtqilv1qwZoqKiMG3atFLdh6snEREREUmbtFdPmmPEe40y4r0qj6SHJ/3zzz8oLi6GtbW1VrmNjQ327dtnoqiIiIiIiKoXSScN9vb2CA0NxdSpU3Hjxg0UFxdj+fLlOHjwIDIyMkwdHhERERFVC/8Y8aiaJJ00AMCyZcsghMALL7wAuVyOOXPmoF+/fjAz0x26SqVCbm6u1iHlzi4iIiIikjomDZJPGgICArB7927k5eXh6tWrOHLkCIqKilC7dm2d1ycmJkKhUGgdRZUcMxERERFRRe3ZswfdunWDl5cXZDIZ1q1bp3VeCIGJEyfC09MTNjY2iIiIQGpqqtY12dnZ6N+/PxwcHODo6IjBgwcjLy+vzLFIPml4xNbWFp6enrh79y62bt2KHj166LwuPj4eSqVS67Cs5FiJiIiI6Hlimp6G/Px8vPjii5g3b57O85999hnmzJmD+fPn4/Dhw7C1tUVkZCQKCws11/Tv3x9//fUXtm3bhk2bNmHPnj0YOnRomeIAJL56EgBs3boVQgjUr18fFy5cwNixY2FtbY29e/fC0rJ06QBXTyIiIiKSNmmvnjTFiPeaWK5aMpkMa9euRc+ePQE87GXw8vLC+++/jw8++AAAoFQq4e7uju+++w59+/bF33//jaCgIKSkpKB58+YAgC1btuCVV17BtWvX4OXlVer2Jd/ToFQqERsbi8DAQERHR6NNmzbYunVrqRMGIiIiIiKp0DX/VqVSlfk+Fy9eRGZmJiIiIjRlCoUCISEhOHjwIADg4MGDcHR01CQMABAREQEzMzMcPny4TO1JPmno06cP0tLSoFKpkJGRgblz50KhUJg6LCIiIiKqNow3PEnX/NvExMQyR5SZmQkAcHd31yp3d3fXnMvMzISbm5vWeQsLCzg7O2uuKS3J7whNRERERGRaxlv1KD5+EsaMGaNVJpfLjXb/Z4VJAxERERFRJZHL5UZJEjw8PAAAWVlZ8PT01JRnZWWhSZMmmmtu3rypVe+ff/5Bdna2pn5pSX54EhERERGRaUlvnwZ/f394eHhgx44dmrLc3FwcPnwYoaGhAIDQ0FDk5OTg2LFjmmt27twJtVqNkJCQMrVn0qTB0NqzRUVFGDduHBo3bgxbW1t4eXkhOjoaN27cMF3ARERERFQNmSZpyMvLw8mTJ3Hy5EkADyc/nzx5EleuXIFMJkNcXBymTZuGDRs24NSpU4iOjoaXl5dmhaUGDRqgS5cuGDJkCI4cOYL9+/djxIgR6Nu3b5lWTgJMnDQYWnu2oKAAx48fx4QJE3D8+HGsWbMG586dQ/fu3U0QKRERERFR5Tp69CiaNm2Kpk2bAgDGjBmDpk2bYuLEh8u2/uc//8HIkSMxdOhQtGjRAnl5ediyZQusra019/jhhx8QGBiIjh074pVXXkGbNm2wcOHCMscimX0anlx7VpeUlBS0bNkSly9fho+PT6nvzX0aiIiIiKRN2vs0jDLiveYY8V6Vp0pNhFYqlZDJZHB0dDR1KERERERUbRhvLkJVVWUmQhcWFmLcuHHo168fHBwcTB0OEREREVG1USV6GoqKitCnTx8IIZCUlGTwWpVKVWJXPQGAA5SIiIiIqHzY0yD5noZHCcPly5exbdu2p/Yy6Nplr6iSYiUiIiKi55H0llytbJJOGh4lDKmpqdi+fTtcXFyeWic+Ph5KpVLrsKyEWImIiIiInlcmHZ6Ul5eHCxcuaL5+tPass7MzPD098e9//xvHjx/Hpk2bUFxcjMzMTACAs7MzrKysdN5T1y57HJpEREREROVXbOoATM6kS64mJyejffv2JcpjYmKQkJAAf39/nfV27dqF8PDwUrfDJVeJiIiIpE3aS672N+K9fjDivSqPSXsawsPDYShnkcgWEkRERERE1VqVWD2JiIiIiMh0qu4EZmNh0kBEREREZBCTBkmvnkRERERERKbHngYiIiIiIoPY02DSnoY9e/agW7du8PLygkwmw7p167TODxw4EDKZTOvo0qWLaYIlIiIiomqKm7uZNGnIz8/Hiy++iHnz5um9pkuXLsjIyNAcP/74YyVGSEREREREJh2eFBUVhaioKIPXyOVyeHh4VFJERERERERPqro9BMYi+YnQycnJcHNzQ/369TF8+HDcuXPH1CERERERUbXC4UmSngjdpUsXvPbaa/D390daWho+/PBDREVF4eDBgzA3Nzd1eERERERE1YKkk4a+fftq/rtx48YIDg5GQEAAkpOT0bFjR511VCoVVCqVVpkAIHuWgRIRERHRc6zq9hAYi+SHJz2udu3aqFmzJi5cuKD3msTERCgUCq2jqBJjJCIiIqLnDYcnVamk4dq1a7hz5w48PT31XhMfHw+lUql1WFZijEREREREzxuTDk/Ky8vT6jW4ePEiTp48CWdnZzg7O2Py5Mno1asXPDw8kJaWhv/85z+oU6cOIiMj9d5TLpdDLpdrlXFoEhERERGVX9XtITAWmRBCmKrx5ORktG/fvkR5TEwMkpKS0LNnT5w4cQI5OTnw8vJC586dMXXqVLi7u5epHTsZ0wYiIiIiKcsz3StpKTQz4r2OGfFelcekSUNlYdJAREREJG1MGqRN0qsnERERERGZHocnMWkgIiIiIjKISQOTBtIrb3H569oNNl4cRERERGRaJl1ydc+ePejWrRu8vLwgk8mwbt06rfN5eXkYMWIEatWqBRsbGwQFBWH+/PmmCZaIiIiIqinu02DSpCE/Px8vvvgi5s2bp/P8mDFjsGXLFixfvhx///034uLiMGLECGzYsKGSIyUiIiKi6otJg0mHJ0VFRSEqKkrv+QMHDiAmJgbh4eEAgKFDh2LBggU4cuQIunfvXklREhERERFVb5LeETosLAwbNmzA9evXIYTArl27cP78eXTu3NnUoRERERFRtVFsxKNqkvRE6K+//hpDhw5FrVq1YGFhATMzMyxatAht27Y1dWjVQkoFJjPnfVSxtu0+qVh9IiIiIuOpusOKjEXyScOhQ4ewYcMG+Pr6Ys+ePYiNjYWXlxciIiJ01lGpVFCpVFplAgC3dyMiIiIiKh/JJg3379/Hhx9+iLVr16Jr164AgODgYJw8eRKff/653qQhMTERkydP1iqzBGD1rAMmIiIioucUexokO6ehqKgIRUVFMDPTDtHc3BxqtVpvvfj4eCiVSq3D8lkHS0RERETPMa6eZNKehry8PFy4cEHz9cWLF3Hy5Ek4OzvDx8cH7dq1w9ixY2FjYwNfX1/s3r0b33//PWbNmqX3nnK5HHK5XKuMQ5PKp2sF6hZwTgIRERHRc0MmhBCmajw5ORnt27cvUR4TE4PvvvsOmZmZiI+Px++//47s7Gz4+vpi6NChGD16NGSy0qcCdmW4lv6nRgXqFhgtCiIiIqoO8kz3SloKjka8V44R71V5TJo0VBYmDeXDpIGIiIgqi7STBjsj3ivPiPeqPJKd00BERERERNIg2dWTiIiIiIikoepOYDYWJg2kV0WGGCkq2LaygvWJiIiIjIdJA4cnERERERGRQSZNGhITE9GiRQvY29vDzc0NPXv2xLlz57SuWbhwIcLDw+Hg4ACZTIacnBzTBEtERERE1ZMoNt5RRZk0adi9ezdiY2Nx6NAhbNu2DUVFRejcuTPy8/M11xQUFKBLly748MMPTRgpEREREVVbaiMeVZSklly9desW3NzcsHv3brRt21br3KM9He7evQtHR8cy3ZdLrlY+zmkgIiKispD0kqvFRnyXNJfwcxogqYnQSuXDV0VnZ2cTR0IAYGnqAIiIiIikwJijisyNeK9KJJmkQa1WIy4uDq1bt0ajRo3KfR+VSgWVSqVVJgCwr4GIiIiIyqXqTkUwGsmsnhQbG4vTp09j5cqVFbpPYmIiFAqF1lFkpBiJiIiIiKojSSQNI0aMwKZNm7Br1y7UqlWrQveKj4+HUqnUOjjMhoiIiIjKjROhTTs8SQiBkSNHYu3atUhOToa/v3+F7ymXyyGXy7XKODSJiIiIiMqNw5NMmzTExsZixYoVWL9+Pezt7ZGZmQkAUCgUsLGxAQBkZmYiMzMTFy5cAACcOnUK9vb28PHx4YTpZ8y9AnWvGS0KIiIiIjI1ky65KtOzFOqSJUswcOBAAEBCQgImT55s8Jqn4ZKr5VORgWJMGoiIiKgsJL3kao4R3yUdJfycBkhqn4ZnhUlD+TBpICIiosoi6aThjhHfJV0k/JwGSGIiNBERERERSZdk9mkgIiIiIpIkToRm0kD62Zo6ACIiIiIpqMJLpRqLSYcnJSYmokWLFrC3t4ebmxt69uyJc+fO6bxWCIGoqCjIZDKsW7eucgMlIiIiIqrGTJo07N69G7GxsTh06BC2bduGoqIidO7cGfn5+SWunT17tt7VloiIiIiInpliIx5laba4GBMmTIC/vz9sbGwQEBCAqVOn4vF1jIQQmDhxIjw9PWFjY4OIiAikpqZW6HF1MenwpC1btmh9/d1338HNzQ3Hjh1D27ZtNeUnT57EF198gaNHj8LT07OywyQiIiKi6sxEcxo+/fRTJCUlYenSpWjYsCGOHj2KQYMGQaFQYNSoUQCAzz77DHPmzMHSpUvh7++PCRMmIDIyEmfOnIG1tbXRYpHUnAalUgkAWpu2FRQU4I033sC8efPg4eFhqtCqpUxTB0BERERUjR04cAA9evRA165dAQB+fn748ccfceTIEQAPexlmz56Njz/+GD169AAAfP/993B3d8e6devQt29fo8UimSVX1Wo14uLi0Lp1azRq1EhTPnr0aISFhWm+EURERERElUptvEOlUiE3N1frUKlUOpsNCwvDjh07cP78eQDAH3/8gX379iEqKgoAcPHiRWRmZiIiIkJTR6FQICQkBAcPHjTqt0AyPQ2xsbE4ffo09u3bpynbsGEDdu7ciRMnTpT6PiqVqsQ3XgDgbAgiIiIiKhcjDk9KTEzE5MmTtcomTZqEhISEEteOHz8eubm5CAwMhLm5OYqLi/HJJ5+gf//+AIDMzIfjQtzd3bXqubu7a84ZiyR6GkaMGIFNmzZh165dqFXrf/sQ79y5E2lpaXB0dISFhQUsLB7mOL169UJ4eLjOeyUmJkKhUGgdRZXxEERERERETxEfHw+lUql1xMfH67z2559/xg8//IAVK1bg+PHjWLp0KT7//HMsXbq0kqMGZEKYbs9uIQRGjhyJtWvXIjk5GXXr1tU6n5mZidu3b2uVNW7cGF999RW6desGf3//EvfU1dPgqVCwp6EcFBWoqzRaFERERFQd5JnulfTpUo34Jlm39M/p7e2N8ePHIzY2VlM2bdo0LF++HGfPnkV6ejoCAgJw4sQJNGnSRHNNu3bt0KRJE3z11VdGC9ukw5NiY2OxYsUKrF+/Hvb29ppuFIVCARsbG3h4eOic/Ozj46MzYQAAuVwOuVyuVVaVE4YaFahbUMG2rSpYn4iIiOi5YKLVkwoKCmBmpj0wyNzcHGr1w93m/P394eHhgR07dmiShtzcXBw+fBjDhw83aiwmTRqSkpIAoMRQoyVLlmDgwIGVHxARERERkUR069YNn3zyCXx8fNCwYUOcOHECs2bNwltvvQUAkMlkiIuLw7Rp01C3bl3NkqteXl7o2bOnUWMx6fCkymJXhTeFM2VPg2sF6t6qYNtERERUvUh6eNJfRnyXbFj657x37x4mTJiAtWvX4ubNm/Dy8kK/fv0wceJEWFk9HBMihMCkSZOwcOFC5OTkoE2bNvjmm29Qr14948UMJg2Sx6SBiIiIqgNJJw2njPgu2VjCz2mAJFZPIiIiIiIi6ZLMPg2km/PTL3kmdYGKTYRuXsG2N1ewPhEREZHRmGgitJQwaSAiIiIiMoRJg2mHJyUmJqJFixawt7eHm5sbevbsiXPnzmnOX7p0CTKZTOexatUqE0ZORERERFR9mDRp2L17N2JjY3Ho0CFs27YNRUVF6Ny5M/Lz8wE83NAiIyND65g8eTLs7OwQFRVlytCJiIiIqLpQG/GooiS1etKtW7fg5uaG3bt3o23btjqvadq0KV566SUsXry41Petyqsn1TJh2xWZ01C/gm1zTgMREVH1IunVkw4Z8V2ylYSf0wBJzWlQKpUAAGdn3VN4jx07hpMnT2LevHmVGZZJXatA3X0VbHtwBepyyVUiIiKi54dkkga1Wo24uDi0bt0ajRo10nnN4sWL0aBBA4SFhem9j0qlgkql0ioTAKpuXwMRERERmVQVHlZkLJLZpyE2NhanT5/GypUrdZ6/f/8+VqxYgcGDDX/+nZiYCIVCoXUUPYuAiYiIiKh6KDbiUUVJImkYMWIENm3ahF27dqFWLd2j+FevXo2CggJER0cbvFd8fDyUSqXWYfksgiYiIiIiqiZMOjxJCIGRI0di7dq1SE5Ohr+/v95rFy9ejO7du8PV1dXgPeVyOeRyuVYZhyYRERERUblV4R4CYzFp0hAbG4sVK1Zg/fr1sLe3R2ZmJgBAoVDAxsZGc92FCxewZ88e/Pbbb6YKtUpqU8H6tStQ17uCbR+tYH0iIiIio+GcBtMOT0pKSoJSqUR4eDg8PT01x08//aR13bfffotatWqhc+fOJoqUiIiIiKj6ktQ+Dc9KVd6nwZQq0tPwYgXbXlvB+kRERFS1SHqfhm1GfJfsJOHnNEAyS64SEREREUkS5zRIY/UkIiIiIiKSLvY0kF7pJqpLREREJCmcCG36idDBwcFwcHCAg4MDQkNDsXnzZs35wsJCxMbGwsXFBXZ2dujVqxeysrJMGDERERERVTvc3M20SUOtWrUwY8YMHDt2DEePHkWHDh3Qo0cP/PXXXwCA0aNHY+PGjVi1ahV2796NGzdu4LXXXjNlyERERERE1Y7kVk9ydnbGzJkz8e9//xuurq5YsWIF/v3vfwMAzp49iwYNGuDgwYNo1apVqe/J1ZOIiIiIpE3SqyetN+K7ZA8JP6cBkpkIXVxcjJUrVyI/Px+hoaE4duwYioqKEBERobkmMDAQPj4+OHjwoAkjJSIiIqJqhcOTTD8R+tSpUwgNDUVhYSHs7Oywdu1aBAUF4eTJk7CysoKjo6PW9e7u7pqdo4mIiIiI6NkzedJQv359nDx5EkqlEqtXr0ZMTAx2795d7vupVCqoVCqtMgGAA5SIiIiIqFyqcA+BsZh8eJKVlRXq1KmDZs2aITExES+++CK++uoreHh44MGDB8jJydG6PisrCx4eHnrvl5iYCIVCoXUUPeNnICIiIqLnmNqIRxVl8qThSWq1GiqVCs2aNYOlpSV27NihOXfu3DlcuXIFoaGheuvHx8dDqVRqHZaVETgRERER0XOqzMOTrly5Am9vb8ieWJFICIGrV6/Cx8en1PeKj49HVFQUfHx8cO/ePaxYsQLJycnYunUrFAoFBg8ejDFjxsDZ2RkODg4YOXIkQkNDDa6cJJfLIZfLtco4NImIiIiIyo3Dk8qeNPj7+yMjIwNubm5a5dnZ2fD390dxcem/qzdv3kR0dDQyMjKgUCgQHByMrVu3olOnTgCAL7/8EmZmZujVqxdUKhUiIyPxzTfflDVkIiIiIqLyY9JQ9n0azMzMkJWVBVdXV63yy5cvIygoCPn5+UYN0Bi4TwMRERGRtEl6n4ZlRnyXfFPCz2lAqXsaxowZAwCQyWSYMGECatSooTlXXFyMw4cPo0mTJkYPkIiIiIjIpKrwBGZjKXXScOLECQAP5y6cOnUKVlZWmnNWVlZ48cUX8cEHHxg/QiIiIiIiU+LwpNInDbt27QIADBo0CF999RUcHByeWVBERERERCQdZZ7TUBVxTgMRERGRtEl6TsN/jfgu+baEn9OAMu/TkJ+fjwkTJiAsLAx16tRB7dq1tY6ySEpKQnBwMBwcHODg4IDQ0FBs3rxZc37YsGEICAiAjY0NXF1d0aNHD5w9e7asIRMRERERlV+xEY8qqsxLrr799tvYvXs33nzzTXh6epbYr6EsatWqhRkzZqBu3boQQmDp0qXo0aMHTpw4gYYNG6JZs2bo378/fHx8kJ2djYSEBHTu3BkXL16Eubl5udslIiIiIqLSK/PwJEdHR/z6669o3br1MwnI2dkZM2fOxODBg0uc+/PPP/Hiiy/iwoULCAgIKPU9OTyJiIiISNokPTzpGyO+S74r4ec0oMw9DU5OTnB2djZ6IMXFxVi1ahXy8/MRGhpa4nx+fj6WLFkCf39/eHt7G719IiIiIiKduORq2ec0TJ06FRMnTkRBQYFRAjh16hTs7Owgl8vxzjvvYO3atQgKCtKc/+abb2BnZwc7Ozts3rwZ27Zt01ru9UkqlQq5ublaR9XM54iIiIiIpKFUw5OaNm2qNXfhwoULEELAz88PlpaWWtceP368TAE8ePAAV65cgVKpxOrVq/Hf//4Xu3fv1iQOSqUSN2/eREZGBj7//HNcv34d+/fvh7W1tc77JSQkYPLkyVpllgD0pxlEREREZGqSHp70lRGHJ70n4ec0oFRJw5Mv4YZMmjSpQgFFREQgICAACxYsKHHuwYMHcHJywn//+1/069dPZ32VSgWVSqVV5qlQgLMaiIiIiKRL0knDl0Z8kxwt4ec0oFRzGiqaCJSFWq0u8dL/iBACQgi95wFALpdDLpdrlTFhICIiIiIqvzJPhDam+Ph4REVFwcfHB/fu3cOKFSuQnJyMrVu3Ij09HT/99BM6d+4MV1dXXLt2DTNmzICNjQ1eeeUVU4ZNRERERNVJFd5fwVjKtXqSrr0ZZDIZrK2tUadOHQwcOBCDBg166r1u3ryJ6OhoZGRkQKFQIDg4GFu3bkWnTp1w48YN7N27F7Nnz8bdu3fh7u6Otm3b4sCBA3Bzcytr2ERERERE5cOkoez7NHz55Zf45JNPEBUVhZYtWwIAjhw5gi1btmD06NG4ePEili1bhq+//hpDhgx5JkGXFfdpICIiIpI2Sc9p+NSI75LjJPycBpS5p2Hfvn2YNm0a3nnnHa3yBQsW4Pfff8cvv/yC4OBgzJkzRzJJAxERERFRuXGfhrL3NNjZ2eHkyZOoU6eOVvmFCxfQpEkT5OXlIS0tDcHBwcjPzzdqsOXFngYiIiIiaZN0T8M0I75Lfizh5zSgzJu7OTs7Y+PGjSXKN27cqNkpOj8/H/b29hWPjoiIiIiITK7Mw5MmTJiA4cOHY9euXZo5DSkpKfjtt98wf/58AMC2bdvQrl27p94rKSkJSUlJuHTpEgCgYcOGmDhxIqKiojTXHDx4EB999BEOHz4Mc3NzNGnSBFu3boWNjU1ZQyciIiIiKjtOhC778CQA2L9/P+bOnYtz584BAOrXr4+RI0ciLCysTPfZuHEjzM3NUbduXQghsHTpUsycORMnTpxAw4YNcfDgQXTp0gXx8fHo1q0bLCws8Mcff6BHjx4l9mIwhMOTiIiIiKRN0sOTJhnxXXKyhJ/TgHIlDc+Ss7MzZs6cicGDB6NVq1bo1KkTpk6dWqF7MmkgIiIikjYmDdJWqjkNubm5Wv9t6Civ4uJirFy5Evn5+QgNDcXNmzdx+PBhuLm5ISwsDO7u7mjXrh327dtX7jaIiIiIiMqs2IhHFVWqOQ1OTk7IyMiAm5sbHB0ddW7uJoSATCZDcXHZvhunTp1CaGgoCgsLYWdnh7Vr1yIoKAiHDh0CACQkJODzzz9HkyZN8P3336Njx444ffo06tatW6Z2iIiIiIjKhUuuli5p2Llzp2ZlpF27dhk1gPr16+PkyZNQKpVYvXo1YmJisHv3bqjVD/91hg0bptldumnTptixYwe+/fZbJCYm6ryfSqWCSqXSKhMAOECJiIiIiKh8SpU0PL4SUmlWRSoLKysrzZ4PzZo1Q0pKCr766iuMHz8eABAUFKR1fYMGDXDlyhW990tMTMTkyZO1yiwBWBk1aiIiIiKqNqrwsCJjKfM+DQCwd+9eDBgwAGFhYbh+/ToAYNmyZUaZb6BWq6FSqeDn5wcvLy/NCk2PnD9/Hr6+vnrrx8fHQ6lUah2WFY6KiIiIiKotzmkoe9Lwyy+/IDIyEjY2Njh+/LhmKJBSqcT06dPLdK/4+Hjs2bMHly5dwqlTpxAfH4/k5GT0798fMpkMY8eOxZw5c7B69WpcuHABEyZMwNmzZzF48GC995TL5XBwcNA6ODSJiIiIiKj8yry527Rp0zB//nxER0dj5cqVmvLWrVtj2rRpZbrXzZs3ER0djYyMDCgUCgQHB2Pr1q3o1KkTACAuLg6FhYUYPXo0srOz8eKLL2Lbtm0ICAgoa9hEREREROXDidBl36ehRo0aOHPmDPz8/GBvb48//vgDtWvXRnp6OoKCglBYWPisYi037tNAREREJG2S3qfhPSO+S35Vtue8fv06xo0bh82bN6OgoAB16tTBkiVL0Lx5cwAPVzCdNGkSFi1ahJycHLRu3RpJSUlGX2m0zMOTPDw8cOHChRLl+/btQ+3atY0SFBERERFRdXf37l20bt0alpaW2Lx5M86cOYMvvvgCTk5Omms+++wzzJkzB/Pnz8fhw4dha2uLyMhIo3+QX+bhSUOGDMF7772Hb7/9FjKZDDdu3MDBgwfxwQcfYMKECUYNjoiIiIjI5Ew0gfnTTz+Ft7c3lixZoinz9/fX/LcQArNnz8bHH3+MHj16AAC+//57uLu7Y926dejbt6/RYilzT8P48ePxxhtvoGPHjsjLy0Pbtm3x9ttvY9iwYRg5cqTRAiMiIiIikgS18Q6VSoXc3Fyt48k9xh7ZsGEDmjdvjt69e8PNzQ1NmzbFokWLNOcvXryIzMxMREREaMoUCgVCQkJw8OBBo34Lypw0yGQyfPTRR8jOzsbp06dx6NAh3Lp1C1OnTi1z40lJSQgODtaschQaGorNmzdrzqelpeHVV1+Fq6srHBwc0KdPH2RlZZW5HSIiIiIiKUhMTIRCodA69G1anJ6erpmfsHXrVgwfPhyjRo3C0qVLAQCZmZkAAHd3d6167u7umnPGUuaJ0Ma0ceNGmJubo27duhBCYOnSpZg5cyZOnDgBPz8/BAcH48UXX9Rs1jZhwgTcuHEDhw4dgplZ6fMdToQmIiIikjZJT4QeZrx3SdWcwhI9C3K5HHK5vMS1VlZWaN68OQ4cOKApGzVqFFJSUnDw4EEcOHAArVu3xo0bN+Dp6am5pk+fPpDJZPjpp5+MFnep5zS89tprpbpuzZo1pW68W7duWl9/8sknSEpKwqFDh3D9+nVcunQJJ06cgIODAwBg6dKlcHJyws6dO7W6YYiIiIiInhkjLrmqL0HQxdPTE0FBQVplDRo0wC+//ALg4QJFAJCVlaWVNGRlZaFJkybGCfj/lfrj+ie7UX799VeYmZmVKC+v4uJirFy5Evn5+QgNDYVKpYJMJtP6plpbW8PMzMwoO08TEREREUlZ69atce7cOa2y8+fPw9fXF8DDSdEeHh7YsWOH5nxubi4OHz6M0NBQo8ZS6p6Gx2dtA8Dq1avx2WefVXiZ1VOnTiE0NBSFhYWws7PD2rVrERQUBFdXV9ja2mLcuHGYPn06hBAYP348iouLkZGRUaE2iYiIiIhKzUSrJ40ePRphYWGYPn06+vTpgyNHjmDhwoVYuHAhgIdzjePi4jBt2jTUrVsX/v7+mDBhAry8vNCzZ0+jxlLmidDGVr9+fZw8eRKHDx/G8OHDERMTgzNnzsDV1RWrVq3Cxo0bYWdnB4VCgZycHLz00ksG5zPompEu4RFyRERERCR1xUY8yqBFixZYu3YtfvzxRzRq1AhTp07F7Nmz0b9/f801//nPfzBy5EgMHToULVq0QF5eHrZs2QJra+sKPfKTyj0R+vHdoI0pIiICAQEBWLBggabs9u3bsLCwgKOjIzw8PPD+++9j7NixOusnJCRoJk4/YgnAyqhREhEREZExSXoidIwRF9VZKuHnNMDkPQ1PUqvVJWaU16xZE46Ojti5cydu3ryJ7t27660fHx8PpVKpdVg+66CJiIiI6PllxH0aqqpSz2nYsGGD1tdqtRo7duzA6dOntcoNvdA/KT4+HlFRUfDx8cG9e/ewYsUKJCcnY+vWrQAezqNo0KABXF1dcfDgQbz33nsYPXo06tevr/eeumakc8FVIiIiIio3E81pkJJSJw26JlMMGzZM62uZTIbi4tJ/V2/evIno6GhkZGRAoVAgODgYW7duRadOnQAA586dQ3x8PLKzs+Hn54ePPvoIo0ePLvX9iYiIiIio4ky6uVtl4eZuRERERNIm6TkNrxvxXfInCT+nAaXuaSAiIiIiqpaq8FwEY5HcRGgiIiIiIpIW9jQQERERERnCidBMGoiIiIiIDOLwJOkMT5oxY4ZmK2wAyM7OxsiRI1G/fn3Y2NjAx8cHo0aNglKpNG2gRERERETVTJmThtq1a+POnTslynNycsq9O3RKSgoWLFiA4OBgTdmNGzdw48YNfP755zh9+jS+++47bNmyBYMHDy5XG0RERERE5VJsxKOKKvPwpEuXLunci0GlUuH69etlDiAvLw/9+/fHokWLMG3aNE15o0aN8Msvv2i+DggIwCeffIIBAwbgn3/+gYUFR1YRERERUSWowi/7xlKuHaG3bt0KhUKh+bq4uBg7duyAn59fmQOIjY1F165dERERoZU06KJUKuHg4MCEgYiIiIioEpVrR+iYmBitc5aWlvDz88MXX3xRpsZXrlyJ48ePIyUl5anX3r59G1OnTsXQoUPL1AYRERERUYVwInTpkwa1+uF3y9/fH0ePHoWLi0uFGr569Sree+89bNu2DdbW1gavzc3NRdeuXREUFISEhASD16pUKqhUKq0yAYB7QhMRERERlU+ZJkIXFRWhdu3ayM7OrnDDx44dw82bN/HSSy/BwsICFhYW2L17N+bMmQMLCwvNvIl79+6hS5cusLe3x9q1a2FpaWnwvomJiVAoFFpHUYWjJSIiIqJqixOhIRNCiLJUcHV1xYEDB1C3bt0KNXzv3j1cvnxZq2zQoEEIDAzEuHHj0KhRI+Tm5iIyMhJyuRy//fYbatSo8dT76upp8FQo2NNAREREJGF5ZXslrVwdjPgmuVPCz2lAmWcUDxgwAIsXL8aMGTMq1LC9vT0aNWqkVWZrawsXFxdNwtC5c2cUFBRg+fLlyM3NRW5uLoCHiYu5ubnO+8rlcsjlcq0yJgxEREREROVX5qThn3/+wbfffovt27ejWbNmsLW11To/a9YsowR2/PhxHD58GABQp04drXMXL14s10pNRERERERlxonQZR+e1L59e/03k8mwc+fOCgdlbHYy9jUQERERSZmkhye9bMR3yb0Sfk4Dypw0VEVMGoiIiIikjUmDtHGXNCIiIiIiQzg8qexJQ/v27SEz8Mm9FIcnERERERGVWxVeKtVYyrRPAwA0adIEL774ouYICgrCgwcPcPz4cTRu3LjcgcyYMQMymQxxcXGasvDwcMhkMq3jnXfeKXcbRERERERUdmXuafjyyy91lickJCAvL69cQaSkpGDBggUIDg4ucW7IkCGYMmWK5uvS7NVARERERGQ07Gkoe0+DPgMGDMC3335b5np5eXno378/Fi1aBCcnpxLna9SoAQ8PD83h4OBgjHCJiIiIiEpHbcSjijJa0nDw4EFYW1uXuV5sbCy6du2KiIgIned/+OEH1KxZE40aNUJ8fDwKCgoqGioREREREZVBmYcnvfbaa1pfCyGQkZGBo0ePYsKECWW618qVK3H8+HGkpKToPP/GG2/A19cXXl5e+PPPPzFu3DicO3cOa9asKWvYRERERETlw+FJZU8aFAqF1tdmZmaoX78+pkyZgs6dO5f6PlevXsV7772Hbdu26e2hGDp0qOa/GzduDE9PT3Ts2BFpaWkICAjQWUelUkGlUmmVCQDcqYGIiIiIyoVJg+k2d1u3bh1effVVmJuba8qKi4shk8lgZmYGlUqldQ4A8vPzYWdnhy1btiAyMlLnfRMSEjB58mStMksAVkZ/AiIiIiIyFklv7tbYiB8/n5LwcxpQ7qTh2LFj+PvvvwEADRs2RNOmTctU/969e7h8+bJW2aBBgxAYGIhx48ahUaNGJers378fbdq0wR9//KFzpSVAd0+Dp0LBngYiIiIiCZN00tDQiG+Sf0n4OQ0o8/Ckmzdvom/fvkhOToajoyMAICcnB+3bt8fKlSvh6upaqvvY29uXSAxsbW3h4uKCRo0aIS0tDStWrMArr7wCFxcX/Pnnnxg9ejTatm2rN2EAALlcDrlcrlXGhIGIiIiIyo3Dk8q+etLIkSNx7949/PXXX8jOzkZ2djZOnz6N3NxcjBo1ymiBWVlZYfv27ejcuTMCAwPx/vvvo1evXti4caPR2iAiIiIioqcr8/AkhUKB7du3o0WLFlrlR44cQefOnZGTk2PM+IzCTsa+BiIiIiIpk/TwpHpGfJc8L+HnNKDMw5PUajUsLS1LlFtaWkKtrsI7VhARERER6cLhSWUfntShQwe89957uHHjhqbs+vXrGD16NDp27GjU4IiIiIiIyPTKPDzp6tWr6N69O/766y94e3tryho1aoQNGzagVq1azyTQiuDwJCIiIiJpk/TwJD8jvktekvBzGlCuJVeFENi+fTvOnj0LAGjQoAEiIiKMHpyxMGkgIiIikjZJJw0+RnyXvCLh5zSgzMOTAEAmk6FTp04YOXIkRo4caZSEYcaMGZDJZIiLi9OUZWZm4s0334SHhwdsbW3x0ksv4ZdffqlwW0REREREVHqlThp27tyJoKAg5ObmljinVCrRsGFD7N27t1xBpKSkYMGCBSX2X4iOjsa5c+ewYcMGnDp1Cq+99hr69OmDEydOlKsdIiIiIqIyKzbiUUWVOmmYPXs2hgwZAgcHhxLnFAoFhg0bhlmzZpU5gLy8PPTv3x+LFi2Ck5OT1rkDBw5g5MiRaNmyJWrXro2PP/4Yjo6OOHbsWJnbISIiIiIqFyYNpU8a/vjjD3Tp0kXv+c6dO5frZT42NhZdu3bVOcQpLCwMP/30E7Kzs6FWq7Fy5UoUFhYiPDy8zO0QEREREVH5lHqfhqysLJ37M2huZGGBW7dulanxlStX4vjx40hJSdF5/ueff8brr78OFxcXWFhYoEaNGli7di3q1Kmj954qlQoqlUqrTADgVGgiIiIiKhduRVb6noYXXngBp0+f1nv+zz//hKenZ6kbvnr1Kt577z388MMPsLa21nnNhAkTkJOTg+3bt+Po0aMYM2YM+vTpg1OnTum9b2JiIhQKhdZRVOqoiIiIiIiewOFJpV9ydeTIkUhOTkZKSkqJl/z79++jZcuWaN++PebMmVOqhtetW4dXX30V5ubmmrLi4mLIZDKYmZnh3LlzqFOnDk6fPo2GDRtqromIiECdOnUwf/58nffV1dPgqVCwp4GIiIhIwiS95KqLEd8k70j4OQ0o9fCkjz/+GGvWrEG9evUwYsQI1K9fHwBw9uxZzJs3D8XFxfjoo49K3XDHjh1L9BgMGjQIgYGBGDduHAoKCgAAZmbanSHm5uZQq/X3Ecnlcsjlcq0yJgxEREREVG4cnlT6pMHd3R0HDhzA8OHDER8fj0cdFDKZDJGRkZg3bx7c3d1L3bC9vT0aNWqkVWZrawsXFxc0atQIRUVFqFOnDoYNG4bPP/8cLi4uWLduHbZt24ZNmzaVuh0iIiIiogqpwsOKjKXUSQMA+Pr64rfffsPdu3dx4cIFCCFQt27dEkulGoOlpSV+++03jB8/Ht26dUNeXh7q1KmDpUuX4pVXXjF6e0REREREpFup5zRUZXYyDlAiIiIikjJJz2mwNeK7ZL6En9OAMvU0EBERERFVO5zTUPolV4mIiIiIqHpiTwMRERERkSGcCG3anoaEhATIZDKtIzAwUHN+4cKFCA8Ph4ODA2QyGXJyckwXLBERERFVT9zczfTDkxo2bIiMjAzNsW/fPs25goICdOnSBR9++KEJIyQiIiIiqt5MPjzJwsICHh4eOs/FxcUBAJKTkysvICIiIiKix3EitOl7GlJTU+Hl5YXatWujf//+uHLliqlDIiIiIiLS4OgkEycNISEh+O6777BlyxYkJSXh4sWLePnll3Hv3j1ThkVERERERI8xadIQFRWF3r17Izg4GJGRkfjtt9+Qk5ODn3/+udz3VKlUyM3N1Tqq5hYaRERERCQFUuhpmDFjBmQymWb4PgAUFhYiNjYWLi4usLOzQ69evZCVlVWBVvQz+fCkxzk6OqJevXq4cOFCue+RmJgIhUKhdRQZMUYiIiIiql7URjzKIyUlBQsWLEBwcLBW+ejRo7Fx40asWrUKu3fvxo0bN/Daa6+VsxXDJJU05OXlIS0tDZ6enuW+R3x8PJRKpdZhacQYiYiIiIgqS15eHvr3749FixbByclJU65UKrF48WLMmjULHTp0QLNmzbBkyRIcOHAAhw4dMnocJk0aPvjgA+zevRuXLl3CgQMH8Oqrr8Lc3Bz9+vUDAGRmZuLkyZOanodTp07h5MmTyM7O1ntPuVwOBwcHrUNWKU9DRERERM8jYw5P0jWUXqVS6W07NjYWXbt2RUREhFb5sWPHUFRUpFUeGBgIHx8fHDx40DgP/hiTJg3Xrl1Dv379UL9+ffTp0wcuLi44dOgQXF1dAQDz589H06ZNMWTIEABA27Zt0bRpU2zYsMGUYRMRERFRNWLM4Um6htInJibqbHflypU4fvy4zvOZmZmwsrKCo6OjVrm7uzsyMzMr/MxPMuk+DStXrjR4PiEhAQkJCZUTDBERERHRMxYfH48xY8Zolcnl8hLXXb16Fe+99x62bdsGa2vrygpPL5Nv7kZEREREJGXG3F9BLpfrTBKedOzYMdy8eRMvvfTS/+IoLsaePXswd+5cbN26FQ8ePEBOTo5Wb0NWVpbejZMrgkkDEREREZEBptiUrWPHjjh16pRW2aBBgxAYGIhx48bB29sblpaW2LFjB3r16gUAOHfuHK5cuYLQ0FCjx8OkgYiIiIhIYuzt7dGoUSOtMltbW7i4uGjKBw8ejDFjxsDZ2RkODg4YOXIkQkND0apVK6PHw6SBiIiIiMiA8u6v8Kx9+eWXMDMzQ69evaBSqRAZGYlvvvnmmbQlE0KYbMPkhIQETJ48Wausfv36OHv2rFaZEAKvvPIKtmzZgrVr16Jnz55lasdOxkVXiYiIiKQsz3SvpE+VacR3SQ8JP6chJu9paNiwIbZv36752sKiZEizZ8+GjC/+REREREQmYfKkwcLCwuAM75MnT+KLL77A0aNHK7RTNBERERFReZhiIrTUmHRzNwBITU2Fl5cXateujf79++PKlSuacwUFBXjjjTcwb968Z7J0FBERERHR0xhzc7eqyqQ9DSEhIfjuu+9Qv359ZGRkYPLkyXj55Zdx+vRp2NvbY/To0QgLC0OPHj1KfU+VSlViK24BgIObiIiIiIjKx6RJQ1RUlOa/g4ODERISAl9fX/z8889wdXXFzp07ceLEiTLdMzExscTkaksAVsYImIiIiIiqHQ5PMvHqSbq0aNECERERuH//PubMmQMzs/+NoCouLoaZmRlefvllJCcn66yvq6fBU6FgTwMRERGRhEl59aR0Iy7IU1vCz2mIySdCPy4vLw9paWl488030adPH7z99tta5xs3bowvv/wS3bp103sPXVtzM2EgIiIiIio/kyYNH3zwAbp16wZfX1/cuHEDkyZNgrm5Ofr16wdXV1edk599fHzg7+9vgmiJiIiIqDri8CQTJw3Xrl1Dv379cOfOHbi6uqJNmzY4dOgQXF1dTRkWEREREZEGkwYJzml4FrgjNBEREZG0SXlOw1kjvksGSvg5DZHUnAYiIiIiIqmpyvsrGAuTBiIiIiIiAzg8SQI7QhMRERERkbSZNGlISEiATCbTOgIDAwEAly5dKnHu0bFq1SpThk1ERERE1UixEY+qyuTDkxo2bIjt27drvraweBiSt7c3MjIytK5duHAhZs6cqbWTNBERERHRs8Q5DRJIGiwsLHTux2Bubl6ifO3atejTpw/s7OwqKzwiIiIiomrP5HMaUlNT4eXlhdq1a6N///64cuWKzuuOHTuGkydPYvDgwZUcIRERERFVZxyeZOJ9GjZv3oy8vDzUr18fGRkZmDx5Mq5fv47Tp0/D3t5e69p3330XycnJOHPmTJnb4T4NRERERNIm5X0aDhvxXTJEws9piKQ2d8vJyYGvry9mzZql1aNw//59eHp6YsKECXj//fcN3kOlUkGlUmmVeSoUYNpAREREJF1MGqTN5MOTHufo6Ih69erhwoULWuWrV69GQUEBoqOjn3qPxMREKBQKraPoWQVMRERERM89Dk+SWNKQl5eHtLQ0eHp6apUvXrwY3bt3h6ur61PvER8fD6VSqXVYPquAiYiIiOi5x6TBxKsnffDBB+jWrRt8fX1x48YNTJo0Cebm5ujXr5/mmgsXLmDPnj347bffSnVPuVwOuVyuVcahSURERERE5WfSpOHatWvo168f7ty5A1dXV7Rp0waHDh3S6lH49ttvUatWLXTu3NmEkRIRERFRdcV9GiQ2EfpZ4epJRERERNIm5YnQO434LtlBws9piKTmNBARERERkfSYfEdoIiIiIiIpq8oTmI2FSQMRERERkQGc0yCB4UnXr1/HgAED4OLiAhsbGzRu3BhHjx7VnBdCYOLEifD09ISNjQ0iIiKQmppqwoiJiIiIiKoXkyYNd+/eRevWrWFpaYnNmzfjzJkz+OKLL+Dk5KS55rPPPsOcOXMwf/58HD58GLa2toiMjERhYaEJIyciIiKi6oL7NJh49aTx48dj//792Lt3r87zQgh4eXnh/fffxwcffAAAUCqVcHd3x3fffYe+ffuWqh2unkREREQkbVJePWmTEd8l/yXh5zTEpD0NGzZsQPPmzdG7d2+4ubmhadOmWLRokeb8xYsXkZmZiYiICE2ZQqFASEgIDh48aIqQiYiIiIiqHZMmDenp6UhKSkLdunWxdetWDB8+HKNGjcLSpUsBAJmZmQAAd3d3rXru7u6ac0REREREzxKHJ5l49SS1Wo3mzZtj+vTpAICmTZvi9OnTmD9/PmJiYsp1T5VKBZVKpVUmAHCAEhERERGVR1V+2TcWk/Y0eHp6IigoSKusQYMGuHLlCgDAw8MDAJCVlaV1TVZWlubckxITE6FQKLSOomcQOxERERFRdWHSpKF169Y4d+6cVtn58+fh6+sLAPD394eHhwd27NihOZ+bm4vDhw8jNDRU5z3j4+OhVCq1Dstn9whERERE9JxTG/Goqkw6PGn06NEICwvD9OnT0adPHxw5cgQLFy7EwoULAQAymQxxcXGYNm0a6tatC39/f0yYMAFeXl7o2bOnznvK5XLI5XKtMg5NIiIiIqLy4vAkEy+5CgCbNm1CfHw8UlNT4e/vjzFjxmDIkCGa80IITJo0CQsXLkROTg7atGmDb775BvXq1St1G1xylYiIiEjapLzk6k9GfJd8XcLPaYjJk4bKwKSBiIiISNqknDSsMOK75BsSfk5DTDo8iYiIiIhI6qryXARjMelEaCIiIiIikj72NBARERERGcCJ0EwaiIiIiIgM4vAkCQxPun79OgYMGAAXFxfY2NigcePGOHr0qOZ8QkICAgMDYWtrCycnJ0RERODw4cMmjJiIiIiIqHoxaU/D3bt30bp1a7Rv3x6bN2+Gq6srUlNT4eTkpLmmXr16mDt3LmrXro379+/jyy+/ROfOnXHhwgW4urqaMHoiIiIiqg44PMnES66OHz8e+/fvx969e0tdJzc3FwqFAtu3b0fHjh1LVYdLrhIRERFJm5SXXF1gxHfJYRJ+TkNMOjxpw4YNaN68OXr37g03Nzc0bdoUixYt0nv9gwcPsHDhQigUCrz44ouVGCkRERERUfVl0qQhPT0dSUlJqFu3LrZu3Yrhw4dj1KhRWLp0qdZ1mzZtgp2dHaytrfHll19i27ZtqFmzpomiJiIiIqLqRG3Eo6oy6fAkKysrNG/eHAcOHNCUjRo1CikpKTh48KCmLD8/HxkZGbh9+zYWLVqEnTt34vDhw3BzcytxT5VKBZVKpVXmqVCAA5SIiIiIpEvKw5PmGnF40ggJP6chJu1p8PT0RFBQkFZZgwYNcOXKFa0yW1tb1KlTB61atcLixYthYWGBxYsX67xnYmIiFAqF1lH0zJ6AiIiIiOj5Z9KkoXXr1jh37pxW2fnz5+Hr62uwnlqtLtGb8Eh8fDyUSqXWYWm0iImIiIiouik24lFVmXTJ1dGjRyMsLAzTp09Hnz59cOTIESxcuBALFy4E8HBY0ieffILu3bvD09MTt2/fxrx583D9+nX07t1b5z3lcjnkcrlWWXUdmlS7gvXTjRIFERERUdVWleciGItJk4YWLVpg7dq1iI+Px5QpU+Dv74/Zs2ejf//+AABzc3OcPXsWS5cuxe3bt+Hi4oIWLVpg7969aNiwoSlDJyIiIiKqNkw6EbqyVNd9GtjTQERERFWFlCdCf27Ed8kPJPychpi0p4GIiIiISOo4PMnEE6GJiIiIiEj62NPwjGVVsP5nFah7poJtc3gSERERUdVe9chYTN7TcP36dQwYMAAuLi6wsbFB48aNcfToUa1r/v77b3Tv3h0KhQK2trZo0aJFib0ciIiIiIieBVMtuZqYmIgWLVrA3t4ebm5u6NmzZ4ntCgoLCxEbGwsXFxfY2dmhV69eyMqq6MfWJZk0abh79y5at24NS0tLbN68GWfOnMEXX3wBJycnzTVpaWlo06YNAgMDkZycjD///BMTJkyAtbW1CSMnIiIiInq2du/ejdjYWBw6dAjbtm1DUVEROnfujPz8fM01o0ePxsaNG7Fq1Srs3r0bN27cwGuvvWb0WEy6etL48eOxf/9+7N27V+81ffv2haWlJZYtW1budky5elJVHp60uYL1iYiIiEpLyqsnTTHiu+TECjznrVu34Obmht27d6Nt27ZQKpVwdXXFihUr8O9//xsAcPbsWTRo0AAHDx5Eq1atjBW2aXsaNmzYgObNm6N3795wc3ND06ZNsWjRIs15tVqNX3/9FfXq1UNkZCTc3NwQEhKCdevWmS5oIiIiIqpWjDk8SaVSITc3V+tQqVSlikOpVAIAnJ2dAQDHjh1DUVERIiIiNNcEBgbCx8cHBw8erOBTazPpROj09HQkJSVhzJgx+PDDD5GSkoJRo0bBysoKMTExuHnzJvLy8jBjxgxMmzYNn376KbZs2YLXXnsNu3btQrt27SolzhoVqDuwgm3XrUDdVRXM2Kvr/hZEREREz0piYiImT56sVTZp0iQkJCQYrKdWqxEXF4fWrVujUaNGAIDMzExYWVnB0dFR61p3d3dkZmYaM2zTJg1qtRrNmzfH9OnTAQBNmzbF6dOnMX/+fMTExECtfrgqbo8ePTB69GgAQJMmTXDgwAHMnz9fZ9KgUqlKZGsCAF9/iYiIiKg8jLl60oT4eIwZM0arTC6XP7VebGwsTp8+jX379hkxmtIz6fAkT09PBAUFaZU1aNBAszJSzZo1YWFhYfCaJyUmJkKhUGgdRc8mfCIiIiKqBtRGPORyORwcHLSOpyUNI0aMwKZNm7Br1y7UqlVLU+7h4YEHDx4gJydH6/qsrCx4eHhU+LkfZ9KkoXXr1iWWjTp//jx8fX0BAFZWVmjRooXBa54UHx8PpVKpdVg+m/CJiIiIiJ4ZIQRGjBiBtWvXYufOnfD399c636xZM1haWmLHjh2asnPnzuHKlSsIDQ01aiwmHZ40evRohIWFYfr06ejTpw+OHDmChQsXYuHChZprxo4di9dffx1t27ZF+/btsWXLFmzcuBHJyck67ymXy0tkaxUdmlSRmRM5FWx7TkXqck4CERERUYWZanO32NhYrFixAuvXr4e9vb1mnoJCoYCNjQ0UCgUGDx6MMWPGwNnZGQ4ODhg5ciRCQ0ONunISYOIlVwFg06ZNiI+PR2pqKvz9/TFmzBgMGTJE65pvv/0WiYmJuHbtGurXr4/JkyejR48epW6johN6oypQN6dCLQPGnfdOREREJE1SXnJ1rBE/iJ1ZhueU6Wl3yZIlGDhwIICHm7u9//77+PHHH6FSqRAZGYlvvvnG6MOTTJ40VAYmDURERETSxqRB2kw6PImIiIiISOpMNTxJSpg0EBEREREZwKShmiQNigrWr8iSrUcr2DYRERERkalVi6SBiIiIiKi81KYOQAJMuk8DAFy/fh0DBgyAi4sLbGxs0LhxYxw9+r/P57OysjBw4EB4eXmhRo0a6NKlC1JTU00YMRERERFVJ8VGPKoqkyYNd+/eRevWrWFpaYnNmzfjzJkz+OKLL+Dk5ATg4YYWPXv2RHp6OtavX48TJ07A19cXERERyM/PN2XoRERERETVhkmHJ3366afw9vbGkiVLNGWP73SXmpqKQ4cO4fTp02jYsCEAICkpCR4eHvjxxx/x9ttvV3rMRERERFS9VOUeAmMxadKwYcMGREZGonfv3ti9ezdeeOEFvPvuu5rN3VQqFQDA2tpaU8fMzAxyuRz79u0rddJgX8E4UypQtyKTqImIiIjI9DinwcTDk9LT05GUlIS6deti69atGD58OEaNGoWlS5cCAAIDA+Hj44P4+HjcvXsXDx48wKeffopr164hIyND5z1VKhVyc3O1Dv5DExERERGVn0mTBrVajZdeegnTp09H06ZNMXToUAwZMgTz588HAFhaWmLNmjU4f/48nJ2dUaNGDezatQtRUVEwM9MdemJiIhQKhdaRXZkPRURERETPFU6ENnHS4OnpiaCgIK2yBg0a4MqVK5qvmzVrhpMnTyInJwcZGRnYsmUL7ty5g9q1a+u8Z3x8PJRKpdbh/EyfgoiIiIieZ2ojHlWVSec0tG7dGufOndMqO3/+PHx9fUtcq1A83KItNTUVR48exdSpU3XeUy6XQy6Xa5WZfF1ZIiIiIqIqzKRJw+jRoxEWFobp06ejT58+OHLkCBYuXIiFCxdqrlm1ahVcXV3h4+ODU6dO4b333kPPnj3RuXPnUrejqmCcygrWJyIiIqKqqyoPKzIWkyYNLVq0wNq1axEfH48pU6bA398fs2fPRv/+/TXXZGRkYMyYMcjKyoKnpyeio6MxYcIEE0ZNRERERNUJkwZAJoQQpg7iWfOXySpU/5aR4iAiIiIi3fIk/Er6RgXfJR+3QsLPaYhJexqIiIiIiKSuKk9gNhYmDUREREREBnB4UjVJGtwrWJ/Dk4iIiIioOjPpaqR+fn6QyWQljtjYWGRnZ2PkyJGoX78+bGxs4OPjg1GjRkGp5FpGRERERFR5uLmbiXsaUlJSUFz8v2/f6dOn0alTJ/Tu3Rs3btzAjRs38PnnnyMoKAiXL1/GO++8gxs3bmD16tUmjJqIiIiIqhPOaZDY6klxcXHYtGkTUlNTIdMxS33VqlUYMGAA8vPzYWFR+nynVQVnvJ+uUG0iIiIiehopr57U04irJ62T8HMaIpk5DQ8ePMDy5csxZswYnQkDACiVSjg4OJQpYQD40k9ERERE5VeVhxUZi2SShnXr1iEnJwcDBw7Uef727duYOnUqhg4dWrmBEREREVG1xuFJEhqeFBkZCSsrK2zcuLHEudzcXHTq1AnOzs7YsGEDLC0t9d5HpVJBpVJplXkqFDBepxIRERERGZuUhyd1NeLwpF8l/JyGmHT1pEcuX76M7du34+233y5x7t69e+jSpQvs7e2xdu1agwkDACQmJkKhUGgdRc8qcCIiIiJ67nH1JIn0NCQkJGDBggW4evWq1nyF3NxcREZGQi6X47fffkONGjWeei/2NBARERFVPVLuaehkxJ6GbRJ+TkNMPqdBrVZjyZIliImJKZEwdO7cGQUFBVi+fDlyc3ORm5sLAHB1dYW5ubnO+8nlcsjlcq0yJgxEREREROVn8qRh+/btuHLlCt566y2t8uPHj+Pw4cMAgDp16midu3jxIvz8/CorRCIiIiKqxjgRWiLDk541OyN2KRERERGR8Ul5eFK4Ed8lkyX8nIZIYiI0ERERERFJl8mHJxERERERSVlVXvXIWJg0EBEREREZwDkNHJ5ERERERERPYdKkwc/PDzKZrMQRGxsLAAgPDy9x7p133jFlyERERERUzXBzNxMPT0pJSUFx8f++fadPn0anTp3Qu3dvTdmQIUMwZcoUzdel2eCNiIiIiMhYODzJxEmDq6ur1tczZsxAQEAA2rVrpymrUaMGPDw8Kjs0IiIiIiL6f5KZ0/DgwQMsX74cb731FmSPrYX7ww8/oGbNmmjUqBHi4+NRUFBgwiiJiIiIqLrh8CQJrZ60bt065OTkYODAgZqyN954A76+vvDy8sKff/6JcePG4dy5c1izZo3e+6hUKqhUKq0yAYDbuxERERFReVTll31jkcyO0JGRkbCyssLGjRv1XrNz50507NgRFy5cQEBAgM5rEhISMHnyZK0ySwBWxgyWiIiIiIxKyjtCNzHijtAnJfychkgiabh8+TJq166NNWvWoEePHnqvy8/Ph52dHbZs2YLIyEid1+jqafBUKNjTQERERCRhUk4ago2YNPwp4ec0RBLDk5YsWQI3Nzd07drV4HUnT54EAHh6euq9Ri6XQy6Xa5UxYSAiIiKi8uLwJAkkDWq1GkuWLEFMTAwsLP4XTlpaGlasWIFXXnkFLi4u+PPPPzF69Gi0bdsWwcHBJoyYiIiIiKh6MXnSsH37dly5cgVvvfWWVrmVlRW2b9+O2bNnIz8/H97e3ujVqxc+/vhjE0VKRERERNURexokMqfhWbMz4jg0IiIiIjI+Kc9pqGfEd8nzEn5OQySzTwMREREREUmTyYcnERERERFJGYcnMWkgIiIiIjJIbeoAJMCkw5P8/Pwgk8lKHLGxsQCAzMxMvPnmm/Dw8ICtrS1eeukl/PLLL6YMmYiIiIio2jFpT0NKSgqKi//X4XP69Gl06tQJvXv3BgBER0cjJycHGzZsQM2aNbFixQr06dMHR48eRdOmTU0VNhERERFVIxyeJLHVk+Li4rBp0yakpqZCJpPBzs4OSUlJePPNNzXXuLi44NNPP8Xbb79d6vty9SQiIiIiaZPy6kkvGPFd8rqEn9MQyaye9ODBAyxfvhxvvfUWZP//DxMWFoaffvoJ2dnZUKvVWLlyJQoLCxEeHm7aYImIiIiIqhHJTIRet24dcnJyMHDgQE3Zzz//jNdffx0uLi6wsLBAjRo1sHbtWtSpU8d0gRIRERFRtcKJ0BJKGhYvXoyoqCh4eXlpyiZMmICcnBxs374dNWvWxLp169CnTx/s3bsXjRs31nkflUoFlUqlVSYAcIASEREREZUH5zRIZE7D5cuXUbt2baxZswY9evQAAKSlpaFOnTo4ffo0GjZsqLk2IiICderUwfz583XeKyEhAZMnT9YqswRg9cyiJyIiIqKKkvKcBjcjzmm4KeHnNEQScxqWLFkCNzc3dO3aVVNWUFAAADAz0w7R3NwcarX+TqL4+HgolUqtw/LZhE1ERERE1UCxEY+qyuTDk9RqNZYsWYKYmBhYWPwvnMDAQNSpUwfDhg3D559/DhcXF6xbtw7btm3Dpk2b9N5PLpdDLpdrlXFoEhERERGVF+c0SKCnYfv27bhy5QreeustrXJLS0v89ttvcHV1Rbdu3RAcHIzvv/8eS5cuxSuvvGKiaImIiIiIKte8efPg5+cHa2trhISE4MiRI5UegyTmNDxr3KeBiIiISNqkPKfBwYjvkrllfM6ffvoJ0dHRmD9/PkJCQjB79mysWrUK586dg5ubm9HiehomDURERERkclJOGoz5LlnW5wwJCUGLFi0wd+5cAA+H9nt7e2PkyJEYP3680eJ6GpMPTyIiIiIiqi5UKhVyc3O1jie3C3jkwYMHOHbsGCIiIjRlZmZmiIiIwMGDBysr5IdENVdYWCgmTZokCgsLK7Uu22bbbJtts222zbbZNtuufiZNmiTwcBsxzTFp0iSd116/fl0AEAcOHNAqHzt2rGjZsmUlRPs/1T5pUCqVAoBQKpWVWpdts222zbbZNttm22ybbVc/hYWFQqlUah36kikpJQ0mX3KViIiIiKi60LU9gD41a9aEubk5srKytMqzsrLg4eHxLMLTi3MaiIiIiIgkyMrKCs2aNcOOHTs0ZWq1Gjt27EBoaGilxsKeBiIiIiIiiRozZgxiYmLQvHlztGzZErNnz0Z+fj4GDRpUqXFU+6RBLpdj0qRJpe4mMlZdts222TbbZttsm22zbbZNT/P666/j1q1bmDhxIjIzM9GkSRNs2bIF7u7ulRpHtdingYiIiIiIyo9zGoiIiIiIyCAmDUREREREZBCTBiIiIiIiMohJAxERERERGcSkoZri/HciIiIiKq1qt+Tq7du38e233+LgwYPIzMwEAHh4eCAsLAwDBw6Eq6uriSOsHHK5HH/88QcaNGhg6lAkKyMjA0lJSdi3bx8yMjJgZmaG2rVro2fPnhg4cCDMzc1NHSIRERFRpahWS66mpKQgMjISNWrUQEREhGZ926ysLOzYsQMFBQXYunUrmjdvXq77X716FZMmTcK3336r8/z9+/dx7NgxODs7IygoSOtcYWEhfv75Z0RHR+us+/fff+PQoUMIDQ1FYGAgzp49i6+++goqlQoDBgxAhw4ddNYbM2aMzvKvvvoKAwYMgIuLCwBg1qxZpXrG/Px8/Pzzz7hw4QI8PT3Rr18/zT10OX78OJycnODv7w8AWLZsGebPn48rV67A19cXI0aMQN++fXXWHTlyJPr06YOXX365VLHpMnfuXBw5cgSvvPIK+vbti2XLliExMRFqtRqvvfYapkyZAguLkrnz0aNHERERgTp16sDGxgYHDx7EG2+8gQcPHmDr1q0ICgrCli1bYG9vX+7YiIzpyJEjJT4MCQ0NRcuWLct9z7t372Ljxo16fy89olarYWZWsuNarVbj2rVr8PHx0VlPCIFLly7B29sbFhYWePDgAdauXQuVSoVXXnkFNWvWLHPMHTp0wJIlS+Dr61umehcvXtT8XmvUqJHBa1UqFczMzGBpaQkASEtLw7fffqv5vTZ48GDN77wn/fLLL4iKikKNGjXKFN/j/vjjDxw7dgzh4eGoXbs2/vrrL8ybNw9qtRqvvvoqIiMjDdbfuXNniQ9Dunfvjrp165Y7JiKqBkQ1EhISIoYOHSrUanWJc2q1WgwdOlS0atWq3Pc/efKkMDMz03nu3LlzwtfXV8hkMmFmZibatm0rbty4oTmfmZmpt+7mzZuFlZWVcHZ2FtbW1mLz5s3C1dVVREREiA4dOghzc3OxY8cOnXVlMplo0qSJCA8P1zpkMplo0aKFCA8PF+3bt9f7TA0aNBB37twRQghx5coV4efnJxQKhWjRooVwdnYWbm5uIj09XW/94OBgsW3bNiGEEIsWLRI2NjZi1KhRIikpScTFxQk7OzuxePFivbGbmZmJunXrihkzZoiMjAy97egydepUYW9vL3r16iU8PDzEjBkzhIuLi5g2bZqYPn26cHV1FRMnTtRZt3Xr1iIhIUHz9bJly0RISIgQQojs7GzRpEkTMWrUKIPtq1Qq8dNPP4m4uDjRt29f0bdvXxEXFyd+/vlnoVKpyvQsT8rMzBSTJ082eM3Vq1fFvXv3SpQ/ePBA7N6922Dd27dvi507d2r+7W/duiVmzJghJk+eLM6cOVPmeP39/cX58+fLXE+tVoudO3eKhQsXio0bN4oHDx7ovfbq1avi1q1bmq/37Nkj3njjDdGmTRvRv39/ceDAAYNtff755+LSpUtljvGRjRs3igkTJoh9+/YJIYTYsWOHiIqKEpGRkWLBggVPrV9QUCAWL14sBg0aJLp06SJeeeUVMWLECLF9+3aD9bKyskSbNm2ETCYTvr6+omXLlqJly5aa3zdt2rQRWVlZ5XomQ7/ThBBCqVSK3r17C2tra+Hm5iYmTJgg/vnnH815Q7/Xzp49K3x9fYWZmZmoU6eOSE9PF82aNRO2traiRo0aombNmgZ/ZtavX6/zMDc3F3PnztV8rcvw4cM1/28UFBSIXr16CTMzM83vnPbt2+v8f+eRdu3aiVWrVgkhhNi3b5+Qy+UiODhYvP7666Jp06aiRo0aen/eZDKZcHBwEEOGDBGHDh3S24Y+v/zyizA3NxcuLi7Czs5ObNu2TTg6OoqIiAgRGRkpzM3NxQ8//KCzblZWlmjZsqUwMzMTFhYWwszMTDRr1kx4eHgIc3NzMXbs2FLFcPjwYTF79mwxfvx4MX78eDF79mxx+PDhMj/L47Kzs8XSpUufel1xcbHe8suXL+utp1arRXp6uigqKhJCPPz9vHLlSrF06VKt3xtl0b59+3L9zkhPTxe///67OHXq1FOvLSws1Pq9d+HCBfHhhx+KAQMGiI8++sjg39/Vq1eL/Pz8Msf3uJMnT4rFixeLtLQ0IYQQp0+fFsOHDxfDhg0TW7ZseWr9HTt2iMmTJ4t33nlHvPvuu+Lzzz8v198CkoZqlTRYW1uLv//+W+/5v//+W1hbW+s9r++P1KPjyy+/1PsHsmfPnqJr167i1q1bIjU1VXTt2lX4+/trfskZ+uMaGhoqPvroIyGEED/++KNwcnISH374oeb8+PHjRadOnXTWTUxMFP7+/iWSCgsLC/HXX3/pfdZHZDKZ5oWjf//+IiwsTOTk5AghhLh3756IiIgQ/fr101vfxsZG80u1adOmYuHChVrnf/jhBxEUFKS37e3bt4v33ntP1KxZU1haWoru3buLjRs36v3D8biAgADxyy+/CCEe/uIzNzcXy5cv15xfs2aNqFOnjt64H/2SFOLhHyRLS0uRmZkphBDi999/F15eXnrbTk1NFbVr1xbW1taiXbt2ok+fPqJPnz6iXbt2wtraWtSpU0ekpqY+9Rn0MfQyd+PGDdGiRQthZmYmzM3NxZtvvqn1AmToZ02Ihy8ECoVCyGQy4eTkJI4ePSr8/f1F3bp1RUBAgLCxsRHHjh3TWferr77SeZibm4v4+HjN1/pERUVpfr7u3LkjQkJChEwmE66ursLMzEwEBgaKmzdv6qzbsmVLsXHjRiGEEOvWrRNmZmaie/fuYty4ceLVV18VlpaWmvO6yGQyYW5uLiIiIsTKlSvLlNjNnz9fWFhYiGbNmgkHBwexbNkyYW9vL95++20xbNgwYWNjI2bPnq23fmpqqvD19RVubm7C29tbyGQy0bVrVxESEiLMzc1F7969NS87T+rVq5cIDQ0VZ8+eLXHu7NmzIiwsTPz73//WWVepVBo89u7da/BnZdSoUaJevXpi1apVYtGiRcLX11d07dpV873LzMwUMplMZ90ePXqI7t27iz///FPExcWJBg0aiB49eogHDx6IwsJC0a1bNzFgwAC9bT96wZfJZHoPfbGbmZlpfq/Fx8eLWrVqiZ07d4r8/Hyxb98+ERAQIMaPH6+3bQcHB82LT7t27cTo0aO1zn/88ceidevWeuOeMmWKaNq0qZDJZKJhw4biyy+/FLdv39bb3uNeeuklMW3aNCHEw78Hjo6OYsqUKZrzn3/+uWjSpInOuq+//rro2bOnUCqVorCwUIwYMUJER0cLIR6+3Lm4uBj8OWWCygS1shNUkpZqlTT4+fkZ/CRj6dKlwtfXV+/5ivyRcnNzE3/++afma7VaLd555x3h4+Mj0tLSDP7Cc3Bw0LxgFhcXCwsLC3H8+HHN+VOnTgl3d3e9cR85ckTUq1dPvP/++5pPLMqTNNSuXVv8/vvvWuf3798vvL299dZ3cXERR48eFUI8/B6cPHlS6/yFCxeEjY3NU9t+8OCB+OmnnzS/qLy8vMSHH35o8MXbxsZG65MnS0tLcfr0ac3Xly5dEjVq1NBZ19fXV/OJsRAPX8RlMpkoKCgQQghx8eJFgwlmRESE6NGjh1AqlSXOKZVK0aNHD9G5c2e99f/44w+Dx08//aT35yU6OlqEhISIlJQUsW3bNtGsWTPRvHlzkZ2dLYQw/CL3KPa3335b5ObmipkzZ4patWqJt99+W3N+0KBBomfPnjrrymQyUatWLeHn56d1yGQy8cILLwg/Pz/h7++vt+3H/82HDx8ugoKCNJ+kXb16VTRr1ky88847Ouva2tpqrg0JCREzZszQOv/111+Lpk2bGmx7yZIlokePHsLS0lK4uLiI9957r1SfBgYFBWkS4p07dwpra2sxb948zfklS5aIBg0a6K0fFRUlhg0bpukFnTFjhoiKihJCCHH+/Hnh5+cnJk2apLOunZ2d1u+DJx09elTY2dnpPPfod5a+w9DvNCGE8PHxEbt27dJ8fevWLdGyZUvRuXNnUVhYaPD3mqurqzhx4oQQQoi8vDwhk8nE3r17Nef3798vfHx89LbdpUsX0bVr1xIvqaX53fb4z1mjRo3EihUrtM6vX79e1KtXT299W1tbzQdQ7u7uOn+vGfqeP2r76NGjYvjw4cLR0VHI5XLRu3fvEr9jdbV98eJFIcTDvyOWlpZaf1vS0tL0tu3g4KD1OzAvL09YWlpqfk8tW7ZM1K9fX2/bTFCZoFZWgkrSVK2Shrlz5wq5XC5GjRol1q9fLw4dOiQOHTok1q9fL0aNGiVsbGy0/tA/ycvLS6xbt07v+RMnTuj9xWFvb69zWEdsbKyoVauW2LNnj8Gk4cKFC5qv7ezstD4Fv3TpksEXWCEe9gpER0eL4OBgcerUKWFpaVnqpOHRJ7teXl4lXqCe1vaAAQPE4MGDhRBC9O7dW3z88cda56dPny4aN26st21dn1pdvnxZTJo0SfPJkT7+/v5i8+bNQoiHL15mZmbi559/1pz/9ddfhZ+fn8667733nmjUqJHYvHmz2Llzp2jfvr0IDw/XnN+yZYsICAjQ27aNjY3Bl80///xTb7IkhOE/Uk97mfPy8tIaKvDoj2KTJk3EnTt3ntrT4OTkpPlZffDggTAzM9O637Fjx8QLL7ygs+6wYcNEkyZNSvyslydJrV+/folP77Zv36436VAoFOKPP/4QQjxMUB/99yMXLlzQmyQ+2XZWVpb49NNPRWBgoDAzMxMtWrQQCxcuFLm5uTrr6kpQH//3v3jxosG2a9SoofVJp0qlEpaWlpo/7uvWrdP7s+ri4iKSk5P13nvXrl3CxcVF5zkHBwfx6aefiuTkZJ3HokWLDP6s2NjYlBgekZubK0JDQ0WHDh1Eenq63vpPfs/s7Oy0fs9duXJFyOVyvW0LIcSsWbOEt7e3Vg9SaZOGR7/XatasqfUiLcTD32uG/v/s0KGD+Oyzz4QQQoSFhZX4MGr16tV6Ex5dv9fu378vvv/+exEeHi7MzMz0/lsLIYSHh4fmg5js7Gwhk8m0ErcjR44IDw8PnXVdXV21vjcFBQXCzMxMMwwxLS3N4PecCSoT1MpKUEmaqlXSIIQQK1euFCEhIcLCwkLzEmZhYSFCQkLETz/9ZLBut27dxIQJE/SeP3nypN5POlq0aCG+//57nediY2OFo6Oj3l94wcHBmpdfIR72LDw+VGHPnj0GP7193I8//ijc3d2FmZlZqV/iGjduLJo2bSrs7OzE6tWrtc7v3r1b7wukEEJcv35d+Pn5ibZt24oxY8YIGxsb0aZNGzFkyBDRtm1bYWVlJX799Ve9bRvq6lar1QZ/6X388cfC1dVVvP3228Lf31+MHz9e+Pj4iKSkJDF//nzh7e1d4lObR+7duyf69Omj+TkJCwvTejnaunWrVgLyJE9PT4NDYTZs2CA8PT31nndxcRGLFy8Wly5d0nn8+uuven9ebG1tS3S1FxUViZ49e4rg4GDx559/Gvzj/PgfCiFKJqmXL182mCiuWbNGeHt7i6+//lpTVpak4dHLnJubm86XOX0vNd27d9d8YhcZGVliGNSiRYtE3bp1Dbat6+dtz549IiYmRtja2gpbW1uddR8l/kI8/JmXyWRaP9fJycmiVq1aetv28vLSGvJ19+5dIZPJNElKenq63ud+9913ha+vr1izZo1Wz5ZSqRRr1qwRfn5+YsSIETrrhoeHi08//VRvXIZ+pwnxMLHT9f/vvXv3RGhoqHjxxRf1/qwFBARovbh98803WknZsWPH9L78Pu7EiRMiKChIDB06VOTn55f6RW7YsGFi9OjRws3NrcTvkWPHjomaNWvqrX/gwAGhUCjEpEmTxNdffy1q1qwpPv74Y/HDDz+IiRMnCkdHR73f18c/edYlNTVVa/jpkwYMGCBCQkLE8uXLRbdu3URkZKRo1aqV+Pvvv8XZs2dFu3bt9H7a/+qrr4pevXqJvLw88eDBAxEXF6c1RPPQoUMGv+dMUJmgVlaCStJU7ZKGRx48eCBu3Lghbty4YXBy5eP27Nmj9fL+pLy8PL2/UKdPn64ZbqDL8OHD9f5xTkpKEps2bdJbNz4+XvNpfmlcvXpVrFu3TuTl5T312oSEBK3jyYlPH3zwgejbt6/Be9y9e1eMGzdOBAUFCWtra2FlZSV8fX3FG2+8IVJSUvTW8/PzK3U3qi7FxcXik08+Ef/617/E9OnThVqtFj/++KPw9vYWLi4uYuDAgU/9Hty/f9/geFN9JkyYIJycnMSsWbPEH3/8ITIzM0VmZqb4448/xKxZs4Szs7Pe4SZCCNG5c2cxdepUvecNvcw1bty4RHInxP8SBx8fH4N/nAMDA7XmwGzatEkzLEuIhy8Whl6AhRDi2rVrokOHDqJLly4iIyOjTEnDK6+8Il599VXh5ORUIvE6dOiQ3qF4Z86cES4uLiI6OlpMnTpV2NnZiQEDBohPPvlEREdHC7lcLpYsWaK37ae9zCmVyhJzch6JjY0VdevWFdOmTRMtW7YUMTExIjAwUGzevFls2bJFNG7cWLz11lt67x0TEyPatWsn/v77b5Genq4Zr/xIcnKy3mGAhYWF4p133hFWVlbCzMxMWFtbC2tra2FmZiasrKzE8OHDRWFhoc66CxcuNDjHJDMzU2tBgCeNHDlS7wtqbm6uCAkJ0fuzNmzYMLFo0SK9905MTBSvvPKK3vOPKygoEMOGDRN169YV5ubmT/1Za9eundbCEE/GMXXqVNGuXTuD9zhw4IBo1apViZ7AF154weCwi6d9GPI0mZmZolOnTsLOzk5ERkaKnJwcMWLECK2FIx5/IX5cWlqaCAgIEBYWFsLS0lI4OjpqFqoQ4uEwOkNDZZigMkGtrASVpKnaJg1Ez9qMGTOEp6enVre8TCYTnp6eBv94CvHw0/ply5bpPZ+dnS2+++47nef+85//6J0vUVRUJLp3727wj3NCQoL48ccf9Z7/8MMPxWuvvab3/CNqtVpMnz5dM/GtNEnDwIEDtY4ne//Gjh0rIiMj9da/cOGC6Nu3r7C3t9e8xFlaWoqwsDCxdu1ag21X5GUuLy9PDBkyRDRq1EgMHTpUqFQqMXPmTGFlZSVkMpkIDw83eO+srCzNC6iZmZnw9fXVGgayatUqMWfOHIMxKJVKsXPnTrFixQqxYsUKsXPnTp1zaowpOzu7xCenj8vNzTX4ybQh6enpWivMlcb69etFXFxchV7KhXj4cn316tVSXXvz5k1x6NAhceDAAa0eOn0uXbqkcwW/ikpLSyvRC61Lfn6+2Lp1q9i4cWOZVw2qaIJqKJligqqfFBNUmUz2TBNUkqZqtU8DkSlcvHhRa+18feu3G8s///yDgoICODg46D1//fr1Mq9j/0hBQQHMzc0hl8tLdf2xY8ewb98+REdHw8nJqVxtPpKfnw9zc3NYW1sbvE4IgZs3b0KtVqNmzZqa9fQrW2FhIYqKikq9n0dqaipUKhUCAwN17h9CJAW5ubk4duyY1u+1Zs2a6f2dYwx3797FjRs30LBhQ53n7927h+PHj6Ndu3ZlvvfFixdhbW0NT0/PUtfZsGEDdu3ahfj4eLi5uZW5zUfS09NhZWWFWrVqPfXaW7duIT09HWq1Gp6envDz8zN4/eXLl+Hj4wOZTFbu+HRJT09HQUHBU39PFRQUYP/+/VCpVGjVqlW59l0haSm5Gw8RGZW/vz9CQ0MRGhqqSRiuXr2Kt956q9z3NFTfwsLC4B/vjIwMTJ48udxt37lzB8OHDy/19c2aNcN7770HJyenCj93dnY23n333adeJ5PJ4O7uDk9PT03C8Cy/5/pYW1vD3t6+1HXr1q2LRo0alfhD/LT69+/fx759+3DmzJkS5woLC/H9998/k7psu/q1/ffff+OXX37RbO7ZtGlT/Pzzz4iLi8POnTufWnfJkiU4e/YsAODs2bMYPnw43nrrrafWdXJygpmZmd76KSkpBhMGQ21fvHjxqQnDk/Xr1auH+/fvY/z48aV+7nPnzpVo+9KlS09NGB7Vz87ORkhICJycnPDpp58+9fvm6+uLs2fPlvt7ri/2mTNnYtasWdizZ4/BupcvX8a1a9dQp04d1KxZs8xtkwSZuKeDqFp62prkz7I+236+2ta1ceT169c15w2tKlORTScrWp9tV722K7LRaEXqsu3q1zZJE4cnET0DGzZsMHg+PT0d77//PoqLi41en21Xr7ZfffVVFBUV4bvvvkNOTg7i4uJw5swZJCcnw8fHB1lZWfDy8jJ6XbZd/doOCwtDhw4dMG3aNKxcuRLvvvsuhg8fjk8++QQAEB8fj2PHjuH33383al22Xf3aJokyddZC9DyqyGZAFa3PtqtX2xXZOLIiddl29Wu7IhuNVnSTUrZdvdomaeKcBqJnwNPTE2vWrIFardZ5HD9+/JnVZ9vVq+379+9rzYGQyWRISkpCt27d0K5dO5w/f/6Z1GXb1a/tR3UAwMzMDNbW1lAoFJpz9vb2UCqVz6Qu265+bZP0MGkgegaaNWuGY8eO6T0vk8kgDIwMrEh9tl292g4MDMTRo0dLlM+dOxc9evRA9+7d9d63InXZdvVr28/PD6mpqZqvDx48CB8fH83XV65c0TuhuCJ12Xb1a5ukiUkD0TMwduxYhIWF6T1fp04d7Nq165nUZ9vVq+1XX30VP/74o85zc+fORb9+/fQmHBWpy7arX9vDhw/Xmu/w5EpfmzdvRocOHYxel21Xv7ZJmjgRmoiIiIiIDGJPAxERERERGcSkgYiIiIiIDGLSQEREREREBjFpICKqZgYOHIiePXsavCY8PBxxcXEGr/nuu+/g6OhotLiIiEi6mDQQEemQmZmJkSNHonbt2pDL5fD29ka3bt2wY8eOSmlfJpNh3bp1Bq9p1aoV3nnnHa2y+fPnQyaT4bvvvtMqHzhwIF5++WUAwFdffVXi/NP4+flh9uzZZapDRETPDyYNRERPuHTpEpo1a4adO3di5syZOHXqFLZs2YL27dsjNjb2mbb94MGDUl/bvn17JCcna5Xt2rUL3t7eJcqTk5M1SxwqFAr2EBARUZkwaSAiesK7774LmUyGI0eOoFevXqhXrx4aNmyIMWPG4NChQ5rrrly5gh49esDOzg4ODg7o06cPsrKyNOd1DQOKi4tDeHi45uvw8HCMGDECcXFxqFmzJiIjI+Hn5wfg4br6MplM8/WT2rdvj3PnziEzM1NTtnv3bowfP14rabh48SIuX76M9u3b64wrPz8f0dHRsLOzg6enJ7744gutdsLDw3H58mWMHj0aMplMs9PrI1u3bkWDBg1gZ2eHLl26ICMjQ9+3loiIqigmDUREj8nOzsaWLVsQGxsLW1vbEucffUKvVqvRo0cPZGdnY/fu3di2bRvS09Px+uuvl7nNpUuXwsrKCvv378f8+fORkpICAFiyZAkyMjI0Xz+pdevWsLS01Gz8dubMGdy/fx+DBw/GnTt3cPHiRQAPex+sra0RGhqq8z5jx47F7t27sX79evz+++9ITk7G8ePHNefXrFmDWrVqYcqUKcjIyNBKCgoKCvD5559j2bJl2LNnD65cuYIPPvigzN8DIiKSNounX0JEVH1cuHABQggEBgYavG7Hjh04deoULl68CG9vbwDA999/j4YNGyIlJQUtWrQodZt169bFZ599VqLc0dERHh4eeuvZ2tqiZcuWSE5ORr9+/ZCcnIw2bdpALpcjLCwMycnJ8Pf3R3JyMkJDQyGXy0vcIy8vD4sXL8by5cvRsWNHAA+TmFq1ammucXZ2hrm5Oezt7UvEU1RUhPnz5yMgIAAAMGLECEyZMqXUz05ERFUDexqIiB4jhCjVdX///Te8vb01CQMABAUFwdHREX///XeZ2mzWrFmZrn9ceHi4ZihScnKyZuhTu3bttMofDU16UlpaGh48eICQkBBNmbOzM+rXr1+q9mvUqKFJGADA09MTN2/eLPuDEBGRpDFpICJ6TN26dSGTyXD27NkK38vMzKxEElJUVFTiOl3DoEqrffv2OH/+PK5fv47k5GS0a9cOwP+ShrS0NFy9elUzCdrYLC0ttb6WyWSlTryIiKjqYNJARPQYZ2dnREZGYt68ecjPzy9xPicnBwDQoEEDXL16FVevXtWcO3PmDHJychAUFAQAcHV1LTEp+OTJk6WKw9LSEsXFxU+9LiwsDFZWVvjmm29QWFio6bVo0aIFbt26hW+//VYzjEmXgIAAWFpa4vDhw5qyu3fv4vz581rXWVlZlSoeIiJ6PjFpICJ6wrx581BcXIyWLVvil19+QWpqKv7++2/MmTNHM5k4IiICjRs3Rv/+/XH8+HEcOXIE0dHRaNeuHZo3bw4A6NChA44ePYrvv/8eqampmDRpEk6fPl2qGPz8/LBjxw5kZmbi7t27eq+zsbFBq1at8PXXX6N169YwNzcH8PAl//HyJ3sEHrGzs8PgwYMxduxY7Ny5E6dPn8bAgQNhZqb958HPzw979uzB9evXcfv27VI9AxERPT+YNBARPaF27do4fvw42rdvj/fffx+NGjVCp06dsGPHDiQlJQF4OAxn/fr1cHJyQtu2bREREYHatWvjp59+0twnMjISEyZMwH/+8x+0aNEC9+7dQ3R0dKli+OKLL7Bt2zZ4e3ujadOmBq9t37497t27p7WUK/BwiNK9e/f0zmd4ZObMmXj55ZfRrVs3REREoE2bNiXmWUyZMgWXLl1CQEAAXF1dS/UMRET0/JAJDj4lIiIiIiID2NNAREREREQGMWkgIiIiIiKDmDQQEREREZFBTBqIiIiIiMggJg1ERERERGQQkwYiIiIiIjKISQMRERERERnEpIGIiIiIiAxi0kBERERERAYxaSAiIiIiIoOYNBARERERkUFMGoiIiIiIyKD/A8/jUrPLN+LCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(heatmap, cmap=\"hot\", cbar=True)\n",
    "plt.title(\"Player Heatmap on Court\")\n",
    "plt.xlabel(\"Court Width\")\n",
    "plt.ylabel(\"Court Height\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9426a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env5",
   "language": "python",
   "name": "env5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
